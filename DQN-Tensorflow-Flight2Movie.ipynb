{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train on Movie Data with trained model on Flight \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training of DQN in Tensorflow\n",
    "--------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/matplotlib/__init__.py:1401: UserWarning:  This call to matplotlib.use() has no effect\n",
      "because the backend has already been chosen;\n",
      "matplotlib.use() must be called *before* pylab, matplotlib.pyplot,\n",
      "or matplotlib.backends is imported for the first time.\n",
      "\n",
      "  warnings.warn(_use_error_msg)\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from util import *\n",
    "from dlg_manager import *\n",
    "from alg import *\n",
    "from agent import *\n",
    "from user_sim import *\n",
    "from state_tracker import *\n",
    "import random\n",
    "from config import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from nlg import *\n",
    "from six.moves import cPickle as pickle\n",
    "import IPython\n",
    "import copy, argparse, json\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 11\n",
      "Sample of dict:\n",
      "- not_sure: 10\n",
      "- thanks: 7\n",
      "- greeting: 4\n",
      "- welcome: 8\n",
      "- confirm_answer: 3\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "act_set_path = './data/dia_acts.txt'\n",
    "act_set = text_to_dict(act_set_path)\n",
    "sample_dict(act_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slot set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 29\n",
      "Sample of dict:\n",
      "- greeting: 9\n",
      "- genre: 8\n",
      "- ticket: 27\n",
      "- state: 21\n",
      "- distanceconstraints: 7\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "slots_set_path = \"./data/slot_set.txt\"\n",
    "slot_set = text_to_dict(slots_set_path)\n",
    "sample_dict(slot_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movie dic: info about movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 991\n",
      "Sample of dict:\n",
      "- 83: {'city': 'boston', 'theater': 'amc loews boston common 19', 'distanceconstraints': 'nearest', 'state': 'ma', 'starttime': '8pm', 'date': 'saturday', 'moviename': 'lolo'}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "movie_kb_path = \"./data/movie_kb.1k.p\"\n",
    "movie_kb = pickle.load(open(movie_kb_path, 'rb'), encoding=\"latin\")\n",
    "sample_dict(movie_kb, sample_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Generator (pretrained)\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "nlg_model_path = './data/trained_model/nlg/lstm_tanh_relu_[1468202263.38]_2_0.610.p'\n",
    "nlg_model = Nlg()\n",
    "nlg_model.load_nlg_model(nlg_model_path)\n",
    "diaact_nl_pairs_path = \"./data/nlg/dia_act_nl_pairs.v6.json\"\n",
    "nlg_model.load_predefine_act_nl_pairs(diaact_nl_pairs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grad_clip: -0.0001\n",
      "dia_slot_val: 2\n",
      "reg_cost: 0.001\n",
      "data_path: .\\data\\movieMultiLine.Annot.Corrected.Final.v3.csv\n",
      "save_check_point: 20\n",
      "slot_rep: 1\n",
      "max_epochs: 200\n",
      "sdgtype: rmsprop\n",
      "init_rnn: 0\n",
      "cv_fold: 6\n",
      "write_model_dir: .\\checkpoints\\template\\07102016\\\n",
      "valid_test: 0\n",
      "pretrained_model_path: None\n",
      "check_point: 20\n",
      "decay_rate: 0.999\n",
      "feed_recurrence: 0\n",
      "hidden_size: 100\n",
      "activation_func: relu\n",
      "momentum: 0.1\n",
      "learning_rate: 0.001\n",
      "batch_size: 16\n",
      "act_set: data/dia_acts.txt\n",
      "smooth_eps: 1e-08\n",
      "split_method: 1\n",
      "slot_set: data/slot_set.txt\n",
      "eva_metric: 2\n",
      "model: lstm_tanh\n",
      "trained_model_path: None\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "model_params = pickle.load(open(nlg_model_path, 'rb'), encoding='latin1')\n",
    "params = model_params['params']\n",
    "params['batch_size'] = 16\n",
    "batch_size = 16\n",
    "save_check_point = 20\n",
    "params['trained_model_path'] = None\n",
    "for k in params:\n",
    "    print(\"{}: {}\".format(k, params[k]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Simulator\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goals length: 128\n",
      "Sample the first goal: \n",
      "{'request_slots': {}, 'diaact': 'request', 'inform_slots': {'city': 'birmingham', 'numberofpeople': '1', 'theater': 'carmike summit 16', 'state': 'al', 'starttime': 'around 2pm', 'date': 'today', 'moviename': 'zootopia'}}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "goal_file_path = './data/user_goals_first_turn_template.part.movie.v1.p'\n",
    "all_goal_set = pickle.load(open(goal_file_path, 'rb'), encoding=\"latin\")\n",
    "print(\"goals length: {}\".format(len(all_goal_set)))\n",
    "print(\"Sample the first goal: \\n{}\".format(all_goal_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split goal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102\n",
      "0\n",
      "26\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# split goal set\n",
    "split_fold = params.get('split_fold', 5)\n",
    "goal_set = {'train':[], 'valid':[], 'test':[], 'all':[]}\n",
    "for u_goal_id, u_goal in enumerate(all_goal_set):\n",
    "    if u_goal_id % split_fold == 1: goal_set['test'].append(u_goal)\n",
    "    else: goal_set['train'].append(u_goal)\n",
    "    goal_set['all'].append(u_goal)\n",
    "print(len(goal_set['train']))\n",
    "print(len(goal_set['valid']))\n",
    "print(len(goal_set['test']))\n",
    "print(len(goal_set['all']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user simulator param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "usersim_params = {}\n",
    "usersim_params['max_turn'] = 40\n",
    "usersim_params['slot_err_prob'] = 0.00\n",
    "# slot_err_mode: 0 for slot_val only; 1 for three errs\n",
    "usersim_params['slot_err_mode'] = 0\n",
    "usersim_params['intent_err_prob'] = 0\n",
    "# run_mode: 0 for default NL; 1 for dia_act; 2 for both\n",
    "usersim_params['run_mode'] = 0\n",
    "# 0 for dia_act level; 1 for NL level\n",
    "usersim_params['act_level'] = 0\n",
    "# train/test/all; default is all\n",
    "usersim_params['learn_phase'] = 'all'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a movie dictionary for user simulator - slot:possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 20\n",
      "Sample of dict:\n",
      "- starttime: ['10:30am', '11:10am', '1:10pm', '1:50pm', '3:45pm', '4:30pm', '5:20pm', '6:30pm', '7:15pm', '9:10pm', '10:30pm', '12:30pm', '9:30pm', '9:30', '8:40pm', '7:00pm', '9:50pm', 'none', 'before 4pm', '12:00', '1:10', '2:40', '3:50', 'around 2pm', '1:30', '4:00', 'night', '11:05am', '1:45pm', '7:20 pm', '4:35pm', '10pm', '10 pm', 'latest showing', '9:00 pm', 'around 6pm', '7:20', '9:10 pm', '8:45 pm', '8:45', '9:50 pm', 'around 3 pm', '12pm', '9:30 pm', '6pm', '9:01pm', '5:30pm', '8:00pm', '10:40pm', '2:30pm', '5:10pm', '10:00pm', '7:15 pm', '7pm', 'around 7pm', 'earliest showing', '12:45pm', '1:15pm', '12:45', '12:35pm', ' 4:05pm', ' 7:05pm', ' 9:55pm', '7:05 pm', 'after dinner', 'after 7:30pm', '10:50pm', '7:50pm', '10:20pm', '8pm', '8:20', '8:15pm', 'between 9 and 10', '10:20', 'after 7pm', '4:40 pm', 'before dinner', '7:10 pm', 'betwenn 8-10 pm', '4 pm', '4:20', '4:20pm', 'from noon to 4pm', '8:30pm', '11:00pm', '11pm', ' Matinee', '4pm to 7pm', '6:55pm', '11:50am', '5:10', '7:50', '10:25', '2:30', '9:25 pm', '2:35 pm', '2:35', 'afternoon', '10:00am', '3:30pm', '6:15pm', '9:00pm', '3:30', '11:30am', '1:05pm', '2:35pm', '4:10pm', '5:40pm', '7:05pm', '8:35pm', '9:55pm', '10:05am', '11:00am', '2:00pm', '4:05pm', '4:50pm', '6:45pm', '7:45pm', '10:45am', '11:15am', '1:00pm', '2:15pm', '4:00pm', '4:45pm', '5:15pm', '7:30pm', 'morning', '7:00 pm', '12:15pm', '3:00pm', '5:45pm', '10:00 pm', '4:50 pm', '7:05', 'around 4pm', '4 PM', '8:00 pm', '8:40', '8:00', '8', '5pm', '5:00 pm', 'around 8 pm', '1:30pm', '4pm', '130pm', 'closest to noon', 'late showing', 'anytime after 7pm', '4:10&&7:00&&9:50pm', '4:40&&7:30&&10:20', '2pm', '2:20 pm', '11:45am', 'around 9pm', '9pm', '8:25pm', '9:05pm', '9:05', '9:45pm', 'around 7 pm', '8:45pm', '5:25pm', '5:25', '317', '10:25pm', '9:55', '6:25', ' 9:00 pm', '7:55pm', '10:45pm', '11:55pm', '10:10am', '1:25pm', '2:20pm', '3:50pm', '7:10pm', '9:35pm', '11:10pm', '12:05am', '7:30', '7:00', 'around 6 pm', '5:20', '6:30', '4:10', '4:40', '10:15pm', '10:15', '12:05pm', '6:25pm', 'after 5 pm', '930pm', '640pm', 'night around 8pm', \"8 o'clock\", '9:20 pm', '9:20', '12:20pm', '3:40pm', '6:50pm', '8:40pm tonight', 'around 8pm', '9:10', '605pm', '6 pm', '2:20PM', '2:20', 'between noon and 4pm', 'early', '10:35', '11:40 am', 'between 2 and 4pm', '6:55', '6:10pm', '7:20pm', '7:25pm', '9:20pm', '2 pm', 'soonest', '12:40pm', '3:40', '6:50', '10:00', '10 o clock', '5:00pm', '7:40pm', '740', '10 cloverfield lane', ' 6:30pm', ' 9:10pm', ' 11:55pm', 'roughly every hour', '9:45 pm', '7', '4:40pm', 'matinee', 'evening', '8:20 pm', 'tonight', '7:30 pm', '8:15 pm', '8:15am', 'after 6 pm', '6:45', ' around 7pm', '4:25 pm', '7:15', '7:10', '10:05', '7:25 pm', 'pm', 'any time', '12:20', 'later in the evening', '12:00pm', 'between 5pm and 6pm', 'between 5 and 6pm', 'around noon', 'soonest upcoming showing', '6:05', '7:25', '1:35 pm', '4:30', 'around 5pm', '2:00 pm', '1:35pm', '9:25pm', '8:10PM', 'evening around 6pm', '6:30 pm', '5:50', '6:40 pm', 'a lot', 'sonnest', '705pm', '635pm', '6:35', '1:15', '7 pm', '6:40pm', 'anytime after 6pm', 'between 8 and 10 pm', '8 pm', '6:00pm', '11:40pm', '1:30 pm', '3:20pm', '8:05', '11:40', 'between 8 and 9pm', '9:25', 'after 7 pm', '5:50pm', '2:25pm', '2:25', 'between say 4pm and 7pm', 'evening around 7', ' 10:30', 'the next', 'the next showing', '2:05 pm', '7:40', '6:00', '8:30', 'between 4pm and 7pm', '730pm', 'early afternoon', ' 7:40pm', ' 10:10pm', '1:50', ' 4:30', ' 7:10', ' 9:50', '2:40pm', 'kinky there', '7:35 pm', '7:35', 'midnight', 'late', 'from 4pm to 7pm', '1:55', '4:25', 'anytime', 'once or twice every hour', '340pm', ' 425pm', '4:25pm', '425pm', '9', '10', 'some time close to that', '11:20am', 'between 8-10 pm', '8:05pm', '10:35pm', 'after 6pm', '11:20', '12:35', 'right now', '1:55pm', '10:05pm', '10:05 pm']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "movie_dict_path = './data/user/dicts.v3.p'\n",
    "movie_dictionary = pickle.load(open(movie_dict_path, 'rb'), encoding=\"latin\")\n",
    "samples = sample_dict(movie_dictionary, sample_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = RuleSimulator(movie_dictionary, act_set, slot_set, goal_set, usersim_params)\n",
    "user.set_nlg_model(nlg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained model path = None\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "agent_params = {}\n",
    "# maximum length of each dialog (default=20, 0=no maximum length)\n",
    "agent_params['max_turn'] = 40\n",
    "# Epsilon to determine stochasticity of epsilon-greedy agent policies\n",
    "agent_params['epsilon'] = 0\n",
    "# run_mode: 0 for default NL; 1 for dia_act; 2 for both\n",
    "agent_params['agent_run_mode'] = 3\n",
    "# 0 for dia_act level; 1 for NL level\n",
    "agent_params['agent_act_level'] = 0\n",
    "\n",
    "############### DQN #################\n",
    "# the size for experience replay\n",
    "agent_params['experience_replay_pool_size'] = 10000\n",
    "# # the hidden size for DQN\n",
    "agent_params['dqn_hidden_size'] = 60\n",
    "agent_params['batch_size'] = 16\n",
    "# # gamma for DQN\n",
    "agent_params['gamma'] = 0.9\n",
    "# # predict model for DQN\n",
    "agent_params['predict_mode'] = True\n",
    "agent_params['trained_model_path'] = params['pretrained_model_path']\n",
    "#####################################\n",
    "print(\"pretrained model path = {}\".format(agent_params['trained_model_path']))\n",
    "# 0: no warm start; 1: warm start for training\n",
    "agent_params['warm_start'] = 1\n",
    "# run_mode: 0 for NL; 1 for dia_act\n",
    "agent_params['cmd_input_mode'] = 0\n",
    "\n",
    "success_rate_threshold = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "act_cardinality  11\n",
      "feasible_actions 43\n",
      "80\n",
      "INFO:tensorflow:Restoring parameters from trained_model/temp/flight_1/model.ckpt\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [80,43] rhs shape= [80,16]\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@q/Variable_2\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](q/Variable_2, save/RestoreV2_2)]]\n\nCaused by op 'save/Assign_2', defined at:\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-e764225970ce>\", line 9, in <module>\n    agent = DQNAgentTF(movie_kb, act_set, slot_set, agent_params, transfer=True, path=\"trained_model/temp/flight_1/model.ckpt\")\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/agent/dqn_agt_tf.py\", line 34, in __init__\n    self.model = DQNTF_all(self.state_dimension, self.hidden_size, self.num_actions, params, path=path)\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\", line 41, in __init__\n    self.load(path)\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\", line 213, in load\n    saver = tf.train.Saver([v for v in all_vars if v.name not in [\"W2, b2\"]])\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [80,43] rhs shape= [80,16]\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@q/Variable_2\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](q/Variable_2, save/RestoreV2_2)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [80,43] rhs shape= [80,16]\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@q/Variable_2\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](q/Variable_2, save/RestoreV2_2)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-e764225970ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgentDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_kb\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0magent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNAgentTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmovie_kb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslot_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"trained_model/temp/flight_1/model.ckpt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_nlg_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlg_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/agent/dqn_agt_tf.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, movie_dict, act_set, slot_set, params, transfer, path)\u001b[0m\n\u001b[1;32m     32\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransfer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransfer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNTF_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m         \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDQNTF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dimension\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_actions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_size, hidden_size, output_size, params, path, logger)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0;31m# self.saver = tf.train.Saver()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path)\u001b[0m\n\u001b[1;32m    212\u001b[0m         \u001b[0mall_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m         \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mall_vars\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"W2, b2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m         \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [80,43] rhs shape= [80,16]\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@q/Variable_2\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](q/Variable_2, save/RestoreV2_2)]]\n\nCaused by op 'save/Assign_2', defined at:\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/usr/local/Cellar/python3/3.6.1/Frameworks/Python.framework/Versions/3.6/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/usr/local/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/usr/local/lib/python3.6/site-packages/tornado/ioloop.py\", line 887, in start\n    handler_func(fd_obj, events)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/usr/local/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/tornado/stack_context.py\", line 275, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 276, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 228, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 390, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/local/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/local/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-18-e764225970ce>\", line 9, in <module>\n    agent = DQNAgentTF(movie_kb, act_set, slot_set, agent_params, transfer=True, path=\"trained_model/temp/flight_1/model.ckpt\")\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/agent/dqn_agt_tf.py\", line 34, in __init__\n    self.model = DQNTF_all(self.state_dimension, self.hidden_size, self.num_actions, params, path=path)\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\", line 41, in __init__\n    self.load(path)\n  File \"/Users/dengl11/Dropbox/1_2017_Spring/CS_234/_CS234_Project_/Github/alg/dqn_transfer_all.py\", line 213, in load\n    saver = tf.train.Saver([v for v in all_vars if v.name not in [\"W2, b2\"]])\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/usr/local/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [80,43] rhs shape= [80,16]\n\t [[Node: save/Assign_2 = Assign[T=DT_FLOAT, _class=[\"loc:@q/Variable_2\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/cpu:0\"](q/Variable_2, save/RestoreV2_2)]]\n"
     ]
    }
   ],
   "source": [
    "# agent = RequestBasicsAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "# agent = AgentDQN(movie_kb, act_set, slot_set, agent_params)\n",
    "# agt = 9\n",
    "agt = 10\n",
    "agent_params['batch_size']  = batch_size\n",
    "if agt == 9:\n",
    "    agent = AgentDQN(movie_kb,batch_size, act_set, slot_set, agent_params)\n",
    "else:\n",
    "    agent = DQNAgentTF(movie_kb, act_set, slot_set, agent_params, transfer=True, path=\"trained_model/temp/flight_1/model.ckpt\")\n",
    "\n",
    "agent.set_nlg_model(nlg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog Manager\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlg_manager = DlgManager(agent, user, act_set, slot_set, movie_kb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running Episodes\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "status = {'successes': 0, 'count': 0, 'cumulative_reward': 0}\n",
    "# the size of validation set\n",
    "simulation_epoch_size = 100\n",
    "# the number of epochs for warm start \n",
    "warm_start_epochs = 200\n",
    "# num_episodes = 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\" Warm_Start Simulation (by Rule Policy) \"\"\"\n",
    "def warm_start_simulation():\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    res = {}\n",
    "    for episode in range(warm_start_epochs):\n",
    "        dlg_manager.init_episode()\n",
    "        episode_over = False\n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dlg_manager.step()\n",
    "            cumulative_reward += reward\n",
    "            if episode_over:\n",
    "                if reward > 0: \n",
    "                    successes += 1\n",
    "#                     print (\"warm_start simulation episode %s: Success\" % (episode))\n",
    "#                 else: print (\"warm_start simulation episode %s: Fail\" % (episode))\n",
    "                cumulative_turns += dlg_manager.state_tracker.turn_count\n",
    "        \n",
    "        if len(agent.experience_replay_pool) >= agent.experience_replay_pool_size:\n",
    "            break\n",
    "    \n",
    "    agent.warm_start = 2\n",
    "    res['success_rate'] = float(successes)/simulation_epoch_size\n",
    "    res['ave_reward'] = float(cumulative_reward)/simulation_epoch_size\n",
    "    res['ave_turns'] = float(cumulative_turns)/simulation_epoch_size\n",
    "    print (\"Warm_Start %s epochs, success rate %s, ave reward %s, ave turns %s\" % (episode+1, res['success_rate'], res['ave_reward'], res['ave_turns']))\n",
    "    print (\"Current experience replay buffer size %s\" % (len(agent.experience_replay_pool)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def simulation_epoch(simulation_epoch_size):\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    res = {}\n",
    "    for episode in range(simulation_epoch_size):\n",
    "        dlg_manager.init_episode()\n",
    "        episode_over = False\n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dlg_manager.step()\n",
    "            cumulative_reward += reward\n",
    "            if episode_over:\n",
    "                if reward > 0: \n",
    "                    successes += 1\n",
    "#                     print (\"simulation episode %s: Success\" % (episode))\n",
    "#                 else: print (\"simulation episode %s: Fail\" % (episode))\n",
    "                cumulative_turns += dlg_manager.state_tracker.turn_count\n",
    "    \n",
    "    res['success_rate'] = float(successes)/simulation_epoch_size\n",
    "    res['ave_reward'] = float(cumulative_reward)/simulation_epoch_size\n",
    "    res['ave_turns'] = float(cumulative_turns)/simulation_epoch_size\n",
    "    print(\"simulation success rate %s, ave reward %s, ave turns %s\" % (res['success_rate'], res['ave_reward'], res['ave_turns']))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episodes(count, status):\n",
    "    successes = 0\n",
    "    cumulative_reward = 0\n",
    "    cumulative_turns = 0\n",
    "    \n",
    "    \n",
    "    if agt >= 9 and params['trained_model_path'] == None and agent.warm_start == 1:\n",
    "        print ('warm_start starting ...')\n",
    "        warm_start_simulation()\n",
    "        print ('warm_start finished, start RL training ...')\n",
    "    \n",
    "    for episode in range(count):\n",
    "        print (\"----------------- Episode: %s ----------------- \" % (episode))\n",
    "        dlg_manager.init_episode()\n",
    "        episode_over = False\n",
    "        \n",
    "        while(not episode_over):\n",
    "            episode_over, reward = dlg_manager.step()\n",
    "            cumulative_reward += reward\n",
    "                \n",
    "            if episode_over:\n",
    "                if reward > 0:\n",
    "                    print (\"Successful Dialog!\")\n",
    "                    successes += 1\n",
    "#                 else: print (\"Failed Dialog!\")\n",
    "                \n",
    "                cumulative_turns += dlg_manager.state_tracker.turn_count\n",
    "        \n",
    "        # simulation\n",
    "        if agt >= 9 and params['trained_model_path'] == None:\n",
    "            agent.predict_mode = True\n",
    "            simulation_res = simulation_epoch(simulation_epoch_size)\n",
    "            \n",
    "            performance_records['success_rate'][episode] = simulation_res['success_rate']\n",
    "            performance_records['ave_turns'][episode] = simulation_res['ave_turns']\n",
    "            performance_records['ave_reward'][episode] = simulation_res['ave_reward']\n",
    "            \n",
    "            if simulation_res['success_rate'] >= best_res['success_rate']:\n",
    "                if simulation_res['success_rate'] >= success_rate_threshold: # threshold = 0.30\n",
    "                    agent.experience_replay_pool = [] \n",
    "                    simulation_epoch(simulation_epoch_size)\n",
    "                \n",
    "#             if simulation_res['success_rate'] > best_res['success_rate']:\n",
    "#                 best_model['model'] = copy.deepcopy(agent)\n",
    "#                 best_res['success_rate'] = simulation_res['success_rate']\n",
    "#                 best_res['ave_reward'] = simulation_res['ave_reward']\n",
    "#                 best_res['ave_turns'] = simulation_res['ave_turns']\n",
    "#                 best_res['epoch'] = episode\n",
    "                \n",
    "            loss = agent.train(batch_size, 1)\n",
    "            if agt == 10: \n",
    "                agent.model.update_target_params()\n",
    "            else: \n",
    "                agent.clone_dqn = copy.deepcopy(agent.dqn)\n",
    "                \n",
    "            agent.predict_mode = False\n",
    "            \n",
    "            print (\"Simulation success rate %s, Ave reward %s, Ave turns %s, Best success rate %s\" % (performance_records['success_rate'][episode], performance_records['ave_reward'][episode], performance_records['ave_turns'][episode], best_res['success_rate']))\n",
    "#             if episode % save_check_point == 0 and params['trained_model_path'] == None: # save the model every 10 episodes\n",
    "#                 save_model(params['write_model_dir'], agt, best_res['success_rate'], best_model['model'], best_res['epoch'], episode)\n",
    "#                 save_performance_records(params['write_model_dir'], agt, performance_records)\n",
    "        curve.append(successes/(episode+1))\n",
    "        losses.append(loss)\n",
    "        print(\"Progress: %s / %s, Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (episode+1, count, successes, episode+1, float(cumulative_reward)/(episode+1), float(cumulative_turns)/(episode+1)))\n",
    "    print(\"Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (successes, count, float(cumulative_reward)/count, float(cumulative_turns)/count))\n",
    "    status['successes'] += successes\n",
    "    status['count'] += count\n",
    "    \n",
    "#     if agt == 9 and params['traained_model_path'] == None:\n",
    "#         save_model(params['write_model_dir'], agt, float(successes)/count, best_model['model'], best_res['epoch'], count)\n",
    "#         save_performance_records(params['write_model_dir'], agt, performance_records)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a Warm Start"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train & Eval\n",
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# performance_records = {}\n",
    "# performance_records['success_rate'] = {}\n",
    "# performance_records['ave_turns'] = {}\n",
    "# performance_records['ave_reward'] = {}\n",
    "\n",
    "# best_model = {}\n",
    "# best_res = {'success_rate': 0, 'ave_reward':float('-inf'), 'ave_turns': float('inf'), 'epoch':0}\n",
    "\n",
    "# curve = []\n",
    "# losses = []\n",
    "agent.warm_start = 0\n",
    "run_episodes(100, status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_learning_curve(curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_loss_curve(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_loss_curve(losses[-100:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.save(agent.model.sess, \"trained_model/tf_400/\", global_step = 400)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
