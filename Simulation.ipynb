{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "from util import *\n",
    "import random\n",
    "from config import *\n",
    "import numpy as np\n",
    "from nlg import *\n",
    "from six.moves import cPickle as pickle\n",
    "import IPython\n",
    "import copy, argparse, json\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Action Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 11\n",
      "Sample of dict:\n",
      "- multiple_choice: 6\n",
      "- confirm_question: 2\n",
      "- request: 0\n",
      "- confirm_answer: 3\n",
      "- deny: 9\n"
     ]
    }
   ],
   "source": [
    "act_set_path = './data/dia_acts.txt'\n",
    "act_set = text_to_dict(act_set_path)\n",
    "sample_dict(act_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### slot set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 29\n",
      "Sample of dict:\n",
      "- theater: 22\n",
      "- price: 18\n",
      "- description: 6\n",
      "- taskcomplete: 16\n",
      "- result: 26\n"
     ]
    }
   ],
   "source": [
    "slots_set_path = \"./data/slot_set.txt\"\n",
    "slot_set = text_to_dict(slots_set_path)\n",
    "sample_dict(slot_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### movie dic: info about movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 991\n",
      "Sample of dict:\n",
      "- 674: {'city': 'los angeles', 'theater': 'regal la live stadium 14', 'distanceconstraints': 'around the city', 'theater_chain': 'amc', 'starttime': '12:00pm', 'date': 'tonight', 'moviename': 'deadpool'}\n"
     ]
    }
   ],
   "source": [
    "movie_kb_path = \"./data/movie_kb.1k.p\"\n",
    "movie_kb = pickle.load(open(movie_kb_path, 'rb'), encoding=\"latin\")\n",
    "sample_dict(movie_kb, sample_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### word dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Language Generator (pretrained)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "code_folding": [
     0,
     83
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Nlg():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def load_nlg_model(self, model_path):\n",
    "        \"\"\" \n",
    "        load the trained NLG model \n",
    "        \"\"\"  \n",
    "        model_params = pickle.load(open(model_path, 'rb'), encoding='latin1')\n",
    "        hidden_size = model_params['model']['Wd'].shape[0]\n",
    "        output_size = model_params['model']['Wd'].shape[1]\n",
    "        if model_params['params']['model'] == 'lstm_tanh': # lstm_tanh\n",
    "            diaact_input_size = model_params['model']['Wah'].shape[0]\n",
    "            input_size = model_params['model']['WLSTM'].shape[0] - hidden_size - 1\n",
    "            rnnmodel = lstm_decoder_tanh(diaact_input_size, input_size, hidden_size, output_size)\n",
    "        \n",
    "        rnnmodel.model = copy.deepcopy(model_params['model'])\n",
    "        model_params['params']['beam_size'] = NlgConfig.beam_size\n",
    "        \n",
    "        self.model = rnnmodel\n",
    "        self.word_dict = copy.deepcopy(model_params['word_dict'])\n",
    "        self.template_word_dict = copy.deepcopy(model_params['template_word_dict'])\n",
    "        self.slot_dict = copy.deepcopy(model_params['slot_dict'])\n",
    "        self.act_dict = copy.deepcopy(model_params['act_dict'])\n",
    "        self.inverse_word_dict = {self.template_word_dict[k]:k for k in self.template_word_dict.keys()}\n",
    "        self.params = copy.deepcopy(model_params['params'])\n",
    "    \n",
    "    def load_predefine_act_nl_pairs(self, path):\n",
    "        \"\"\" \n",
    "        Load some pre-defined Dia_Act&NL Pairs from file \n",
    "        \"\"\"\n",
    "        self.diaact_nl_pairs = json.load(open(path, 'r'), encoding=\"latin1\")\n",
    "        \n",
    "    def convert_diaact_to_nl(self, dia_act, turn_msg):\n",
    "        \"\"\" \n",
    "        Convert Dia_Act into NL: Rule + Model \n",
    "        \"\"\"\n",
    "        \n",
    "        sentence = \"\"\n",
    "        boolean_in = False\n",
    "        \n",
    "        # remove I do not care slot in task(complete)\n",
    "        if dia_act['diaact'] == 'inform' and 'taskcomplete' in dia_act['inform_slots'].keys() and dia_act['inform_slots']['taskcomplete'] != NlgConfig.NO_VALUE_MATCH:\n",
    "            inform_slot_set = list(dia_act['inform_slots'].keys())\n",
    "            for slot in inform_slot_set:\n",
    "                if dia_act['inform_slots'][slot] == NlgConfig.I_DO_NOT_CARE: del dia_act['inform_slots'][slot]\n",
    "        \n",
    "        if dia_act['diaact'] in self.diaact_nl_pairs['dia_acts'].keys():\n",
    "            for ele in self.diaact_nl_pairs['dia_acts'][dia_act['diaact']]:\n",
    "                if set(ele['inform_slots']) == set(dia_act['inform_slots'].keys()) and set(ele['request_slots']) == set(dia_act['request_slots'].keys()):\n",
    "                    sentence = self.diaact_to_nl_slot_filling(dia_act, ele['nl'][turn_msg])\n",
    "                    boolean_in = True\n",
    "                    break\n",
    "        \n",
    "        if dia_act['diaact'] == 'inform' and 'taskcomplete' in dia_act['inform_slots'].keys() and dia_act['inform_slots']['taskcomplete'] == NlgConfig.NO_VALUE_MATCH:\n",
    "            sentence = \"Oh sorry, there is no ticket available.\"\n",
    "        \n",
    "        if boolean_in == False: sentence = self.translate_diaact(dia_act)\n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def diaact_to_nl_slot_filling(self, dia_act, template_sentence):\n",
    "        \"\"\" Replace the slots with its values \"\"\"\n",
    "        \n",
    "        sentence = template_sentence\n",
    "        counter = 0\n",
    "        for slot in dia_act['inform_slots'].keys():\n",
    "            slot_val = dia_act['inform_slots'][slot]\n",
    "            if slot_val == NlgConfig.NO_VALUE_MATCH:\n",
    "                sentence = slot + \" is not available!\"\n",
    "                break\n",
    "            elif slot_val == NlgConfig.I_DO_NOT_CARE:\n",
    "                counter += 1\n",
    "                sentence = sentence.replace(\"$\"+slot+\"$\", \"\", 1)\n",
    "                continue\n",
    "            \n",
    "            \n",
    "        \n",
    "        if counter > 0 and counter == len(dia_act['inform_slots']):\n",
    "            sentence = NlgConfig.I_DO_NOT_CARE\n",
    "        \n",
    "        return sentence\n",
    "    \n",
    "    def post_process(self, pred_template, slot_val_dict, slot_dict):\n",
    "        \"\"\" fill the slot in the template sentence \"\"\"\n",
    "        \n",
    "        sentence = pred_template\n",
    "        suffix = \"_PLACEHOLDER\"\n",
    "        \n",
    "        for slot in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict[slot]\n",
    "            slot_placeholder = slot + suffix\n",
    "            if slot == 'result' or slot == 'numberofpeople': continue\n",
    "            if slot_vals == NlgConfig.NO_VALUE_MATCH: continue\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, slot_vals, 1)\n",
    "            sentence = tmp_sentence\n",
    "                \n",
    "        if 'numberofpeople' in slot_val_dict.keys():\n",
    "            slot_vals = slot_val_dict['numberofpeople']\n",
    "            slot_placeholder = 'numberofpeople' + suffix\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, slot_vals, 1)\n",
    "            sentence = tmp_sentence\n",
    "    \n",
    "        for slot in slot_dict.keys():\n",
    "            slot_placeholder = slot + suffix\n",
    "            tmp_sentence = sentence.replace(slot_placeholder, '')\n",
    "            sentence = tmp_sentence\n",
    "            \n",
    "        return sentence\n",
    "    \n",
    "    \n",
    "    def translate_diaact(self, dia_act):\n",
    "        \"\"\" prepare the diaact into vector representation, and generate the sentence by Model \"\"\"\n",
    "        \n",
    "        word_dict = self.word_dict\n",
    "        template_word_dict = self.template_word_dict\n",
    "        act_dict = self.act_dict\n",
    "        slot_dict = self.slot_dict\n",
    "        inverse_word_dict = self.inverse_word_dict\n",
    "    \n",
    "        act_rep = np.zeros((1, len(act_dict)))\n",
    "        act_rep[0, act_dict[dia_act['diaact']]] = 1.0\n",
    "    \n",
    "        slot_rep_bit = 2\n",
    "        slot_rep = np.zeros((1, len(slot_dict)*slot_rep_bit)) \n",
    "    \n",
    "        suffix = \"_PLACEHOLDER\"\n",
    "        if self.params['dia_slot_val'] == 2 or self.params['dia_slot_val'] == 3:\n",
    "            word_rep = np.zeros((1, len(template_word_dict)))\n",
    "            words = np.zeros((1, len(template_word_dict)))\n",
    "            words[0, template_word_dict['s_o_s']] = 1.0\n",
    "        else:\n",
    "            word_rep = np.zeros((1, len(word_dict)))\n",
    "            words = np.zeros((1, len(word_dict)))\n",
    "            words[0, word_dict['s_o_s']] = 1.0\n",
    "    \n",
    "        for slot in dia_act['inform_slots'].keys():\n",
    "            slot_index = slot_dict[slot]\n",
    "            slot_rep[0, slot_index*slot_rep_bit] = 1.0\n",
    "        \n",
    "            for slot_val in dia_act['inform_slots'][slot]:\n",
    "                if self.params['dia_slot_val'] == 2:\n",
    "                    slot_placeholder = slot + suffix\n",
    "                    if slot_placeholder in template_word_dict.keys():\n",
    "                        word_rep[0, template_word_dict[slot_placeholder]] = 1.0\n",
    "                elif self.params['dia_slot_val'] == 1:\n",
    "                    if slot_val in word_dict.keys():\n",
    "                        word_rep[0, word_dict[slot_val]] = 1.0\n",
    "                    \n",
    "        for slot in dia_act['request_slots'].keys():\n",
    "            slot_index = slot_dict[slot]\n",
    "            slot_rep[0, slot_index*slot_rep_bit + 1] = 1.0\n",
    "    \n",
    "        if self.params['dia_slot_val'] == 0 or self.params['dia_slot_val'] == 3:\n",
    "            final_representation = np.hstack([act_rep, slot_rep])\n",
    "        else: # dia_slot_val = 1, 2\n",
    "            final_representation = np.hstack([act_rep, slot_rep, word_rep])\n",
    "    \n",
    "        dia_act_rep = {}\n",
    "        dia_act_rep['diaact'] = final_representation\n",
    "        dia_act_rep['words'] = words\n",
    "    \n",
    "        #pred_ys, pred_words = nlg_model['model'].forward(inverse_word_dict, dia_act_rep, nlg_model['params'], predict_model=True)\n",
    "        pred_ys, pred_words = self.model.beam_forward(inverse_word_dict, dia_act_rep, self.params, predict_model=True)\n",
    "        pred_sentence = ' '.join(pred_words[:-1])\n",
    "        sentence = self.post_process(pred_sentence, dia_act['inform_slots'], slot_dict)\n",
    "            \n",
    "        return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nlg_model_path = './data/trained_model/nlg/lstm_tanh_relu_[1468202263.38]_2_0.610.p'\n",
    "nlg_model = Nlg()\n",
    "nlg_model.load_nlg_model(nlg_model_path)\n",
    "diaact_nl_pairs_path = \"./data/nlg/dia_act_nl_pairs.v6.json\"\n",
    "nlg_model.load_predefine_act_nl_pairs(diaact_nl_pairs_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['grad_clip', 'dia_slot_val', 'reg_cost', 'data_path', 'save_check_point', 'slot_rep', 'max_epochs', 'sdgtype', 'init_rnn', 'cv_fold', 'write_model_dir', 'valid_test', 'pretrained_model_path', 'check_point', 'decay_rate', 'feed_recurrence', 'hidden_size', 'activation_func', 'momentum', 'learning_rate', 'batch_size', 'act_set', 'smooth_eps', 'split_method', 'slot_set', 'eva_metric', 'model'])\n"
     ]
    }
   ],
   "source": [
    "model_params = pickle.load(open(nlg_model_path, 'rb'), encoding='latin1')\n",
    "params = model_params['params']\n",
    "print(params.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Simulator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "goals length: 128\n",
      "Sample the first goal: \n",
      "{'request_slots': {}, 'diaact': 'request', 'inform_slots': {'city': 'birmingham', 'numberofpeople': '1', 'theater': 'carmike summit 16', 'state': 'al', 'starttime': 'around 2pm', 'date': 'today', 'moviename': 'zootopia'}}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "goal_file_path = './data/user_goals_first_turn_template.part.movie.v1.p'\n",
    "all_goal_set = pickle.load(open(goal_file_path, 'rb'), encoding=\"latin\")\n",
    "print(\"goals length: {}\".format(len(all_goal_set)))\n",
    "print(\"Sample the first goal: \\n{}\".format(all_goal_set[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split goal set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split goal set\n",
    "split_fold = params.get('split_fold', 5)\n",
    "goal_set = {'train':[], 'valid':[], 'test':[], 'all':[]}\n",
    "for u_goal_id, u_goal in enumerate(all_goal_set):\n",
    "    if u_goal_id % split_fold == 1: goal_set['test'].append(u_goal)\n",
    "    else: goal_set['train'].append(u_goal)\n",
    "    goal_set['all'].append(u_goal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### user simulator param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "usersim_params = {}\n",
    "usersim_params['max_turn'] = 40\n",
    "usersim_params['slot_err_prob'] = 0.05\n",
    "# slot_err_mode: 0 for slot_val only; 1 for three errs\n",
    "usersim_params['slot_err_mode'] = 0\n",
    "usersim_params['intent_err_prob'] = 0\n",
    "# run_mode: 0 for default NL; 1 for dia_act; 2 for both\n",
    "usersim_params['run_mode'] = 0\n",
    "# 0 for dia_act level; 1 for NL level\n",
    "usersim_params['act_level'] = 0\n",
    "# train/test/all; default is all\n",
    "usersim_params['learn_phase'] = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class UserSimulator:\n",
    "    def set_nlg_model(self, nlg_model):\n",
    "        self.nlg_model = nlg_model  \n",
    "    \n",
    "    def set_nlu_model(self, nlu_model):\n",
    "        self.nlu_model = nlu_model\n",
    "    \n",
    "    def add_nl_to_action(self, user_action):\n",
    "        \"\"\" \n",
    "        Add NL to User Dia_Act \n",
    "        \"\"\"\n",
    "        \n",
    "        user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(user_action, 'usr')\n",
    "        user_action['nl'] = user_nlg_sentence\n",
    "        \n",
    "        if self.act_level == 1:\n",
    "            user_nlu_res = self.nlu_model.generate_dia_act(user_action['nl']) # NLU\n",
    "            if user_nlu_res != None:\n",
    "                #user_nlu_res['diaact'] = user_action['diaact'] # or not?\n",
    "                user_action.update(user_nlu_res)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RuleSimulator(UserSimulator):\n",
    "    \"\"\" \n",
    "    A rule-based user simulator for testing dialog policy \n",
    "    \"\"\"\n",
    "    def __init__(self, movie_dict = None, act_set = None, slot_set = None, start_set = None, params = None):\n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.start_set = start_set\n",
    "        self.max_turn = params['max_turn']\n",
    "        self.slot_err_prob = params['slot_err_prob']\n",
    "        self.slot_err_mode = params['slot_err_mode']\n",
    "        self.intent_err_prob = params['intent_err_prob']\n",
    "        self.run_mode = params['run_mode']\n",
    "        self.act_level = params['act_level']\n",
    "        self.learn_phase = params['learn_phase']\n",
    "     \n",
    "    \n",
    "    def _sample_goal(self, goal_set):\n",
    "        return np.random.choice(self.start_set[self.learn_phase])\n",
    "        \n",
    "    def init_episode(self):\n",
    "        \"\"\" \n",
    "        Initialize a new episode (dialog) \n",
    "            state['hist_slots']: keeps all the informed_slots\n",
    "            state['rest_slots']: keep all the slots (which is still in the stack yet)\n",
    "        \"\"\"\n",
    "        self.state = {}\n",
    "        self.state['hist_slots'] = {}\n",
    "        self.state['inform_slots'] = {}\n",
    "        self.state['request_slots'] = {}\n",
    "        self.state['rest_slots'] = []\n",
    "        self.state['turn'] = 0\n",
    "        self.episode_done = False\n",
    "        self.status = UserSimulatorConfig.NO_OUTCOME_YET\n",
    "        \n",
    "        self.goal = self._sample_goal(self.start_set)\n",
    "        self.goal['request_slots']['ticket'] = 'UNK'\n",
    "        self.constraint_check = UserConfig.CONSTRAINT_CHECK_FAILURE\n",
    "        \n",
    "        # sample first action\n",
    "        user_action = self._sample_action()\n",
    "        assert (self.episode_done != 1),' but we just started'\n",
    "        return user_action\n",
    "\n",
    "    def _sample_action(self):\n",
    "        \"\"\" \n",
    "        randomly sample a start action based on user goal \n",
    "        \"\"\"\n",
    "        \n",
    "        self.state['diaact'] = random.choice(list(UserConfig.start_dia_acts.keys()))\n",
    "        \n",
    "        # \"sample\" informed slots\n",
    "        if len(self.goal['inform_slots']) > 0:\n",
    "            known_slot = random.choice(list(self.goal['inform_slots'].keys()))\n",
    "            self.state['inform_slots'][known_slot] = self.goal['inform_slots'][known_slot]\n",
    "\n",
    "            if 'moviename' in self.goal['inform_slots'].keys(): # 'moviename' must appear in the first user turn\n",
    "                self.state['inform_slots']['moviename'] = self.goal['inform_slots']['moviename']\n",
    "                \n",
    "            for slot in self.goal['inform_slots'].keys():\n",
    "                if known_slot == slot or slot == 'moviename': continue\n",
    "                self.state['rest_slots'].append(slot)\n",
    "        \n",
    "        self.state['rest_slots'].extend(self.goal['request_slots'].keys())\n",
    "        \n",
    "        # \"sample\" a requested slot\n",
    "        request_slot_set = list(self.goal['request_slots'].keys())\n",
    "        request_slot_set.remove('ticket')\n",
    "        if len(request_slot_set) > 0:\n",
    "            request_slot = random.choice(request_slot_set)\n",
    "        else:\n",
    "            request_slot = 'ticket'\n",
    "        self.state['request_slots'][request_slot] = 'UNK'\n",
    "        \n",
    "        if len(self.state['request_slots']) == 0:\n",
    "            self.state['diaact'] = 'inform'\n",
    "\n",
    "        if (self.state['diaact'] in ['thanks','closing']): self.spisode_done = True\n",
    "        else: self.spisode_done = False \n",
    "\n",
    "        sample_action = {}\n",
    "        sample_action['diaact'] = self.state['diaact']\n",
    "        sample_action['inform_slots'] = self.state['inform_slots']\n",
    "        sample_action['request_slots'] = self.state['request_slots']\n",
    "        sample_action['turn'] = self.state['turn']\n",
    "        \n",
    "        self.add_nl_to_action(sample_action)\n",
    "        return sample_action\n",
    "    \n",
    "        \n",
    "        \n",
    "    def corrupt(self, user_action):\n",
    "        \"\"\" Randomly corrupt an action with error probs (slot_err_probability and slot_err_mode) on Slot and Intent (intent_err_probability). \"\"\"\n",
    "        \n",
    "        for slot in user_action['inform_slots'].keys():\n",
    "            slot_err_prob_sample = random.random()\n",
    "            if slot_err_prob_sample < self.slot_err_prob: # add noise for slot level\n",
    "                if self.slot_err_mode == 0: # replace the slot_value only\n",
    "                    if slot in self.movie_dict.keys(): user_action['inform_slots'][slot] = random.choice(self.movie_dict[slot])\n",
    "                elif self.slot_err_mode == 1: # combined\n",
    "                    slot_err_random = random.random()\n",
    "                    if slot_err_random <= 0.33:\n",
    "                        if slot in self.movie_dict.keys(): user_action['inform_slots'][slot] = random.choice(self.movie_dict[slot])\n",
    "                    elif slot_err_random > 0.33 and slot_err_random <= 0.66:\n",
    "                        del user_action['inform_slots'][slot]\n",
    "                        random_slot = random.choice(self.movie_dict.keys())\n",
    "                        user_action[random_slot] = random.choice(self.movie_dict[random_slot])\n",
    "                    else:\n",
    "                        del user_action['inform_slots'][slot]\n",
    "                elif self.slot_err_mode == 2: #replace slot and its values\n",
    "                    del user_action['inform_slots'][slot]\n",
    "                    random_slot = random.choice(self.movie_dict.keys())\n",
    "                    user_action[random_slot] = random.choice(self.movie_dict[random_slot])\n",
    "                elif self.slot_err_mode == 3: # delete the slot\n",
    "                    del user_action['inform_slots'][slot]   \n",
    "        \n",
    "    def next(self, system_action):\n",
    "        \"\"\" Generate next User Action based on last System Action \"\"\"\n",
    "        \n",
    "        self.state['turn'] += 2\n",
    "        self.spisode_done = False\n",
    "        self.dialog_status = UserSimulatorConfig.NO_OUTCOME_YET\n",
    "        \n",
    "        sys_act = system_action['diaact']\n",
    "        \n",
    "        if (self.max_turn > 0 and self.state['turn'] > self.max_turn):\n",
    "            self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "            self.spisode_done = True\n",
    "            self.state['diaact'] = \"closing\"\n",
    "        else:\n",
    "            self.state['hist_slots'].update(self.state['inform_slots'])\n",
    "            self.state['inform_slots'].clear()\n",
    "\n",
    "            if sys_act == \"inform\":\n",
    "                self.response_inform(system_action)\n",
    "            elif sys_act == \"multiple_choice\":\n",
    "                self.response_multiple_choice(system_action)\n",
    "            elif sys_act == \"request\":\n",
    "                self.response_request(system_action) \n",
    "            elif sys_act == \"thanks\":\n",
    "                self.response_thanks(system_action)\n",
    "            elif sys_act == \"confirm_answer\":\n",
    "                self.response_confirm_answer(system_action)\n",
    "            elif sys_act == \"closing\":\n",
    "                self.spisode_done = True\n",
    "                self.state['diaact'] = \"thanks\"\n",
    "\n",
    "        self.corrupt(self.state)\n",
    "        \n",
    "        response_action = {}\n",
    "        response_action['diaact'] = self.state['diaact']\n",
    "        response_action['inform_slots'] = self.state['inform_slots']\n",
    "        response_action['request_slots'] = self.state['request_slots']\n",
    "        response_action['turn'] = self.state['turn']\n",
    "        response_action['nl'] = \"\"\n",
    "        \n",
    "        # add NL to dia_act\n",
    "        self.add_nl_to_action(response_action)                       \n",
    "        return response_action, self.spisode_done, self.dialog_status\n",
    "    \n",
    "    def response_confirm_answer(self, system_action):\n",
    "        \"\"\" Response for Confirm_Answer (System Action) \"\"\"\n",
    "    \n",
    "        if len(self.state['rest_slots']) > 0:\n",
    "            request_slot = random.choice(self.state['rest_slots'])\n",
    "\n",
    "            if request_slot in self.goal['request_slots'].keys():\n",
    "                self.state['diaact'] = \"request\"\n",
    "                self.state['request_slots'][request_slot] = \"UNK\"\n",
    "            elif request_slot in self.goal['inform_slots'].keys():\n",
    "                self.state['diaact'] = \"inform\"\n",
    "                self.state['inform_slots'][request_slot] = self.goal['inform_slots'][request_slot]\n",
    "                if request_slot in self.state['rest_slots']:\n",
    "                    self.state['rest_slots'].remove(request_slot)\n",
    "        else:\n",
    "            self.state['diaact'] = \"thanks\"\n",
    "            \n",
    "    def response_thanks(self, system_action):\n",
    "        \"\"\" Response for Thanks (System Action) \"\"\"\n",
    "        \n",
    "        self.spisode_done = True\n",
    "        self.dialog_status = DlgManagerConfig.SUCCESS_DIALOG\n",
    "\n",
    "        request_slot_set = copy.deepcopy(list(self.state['request_slots'].keys()))\n",
    "        if 'ticket' in request_slot_set:\n",
    "            request_slot_set.remove('ticket')\n",
    "        rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "        if 'ticket' in rest_slot_set:\n",
    "            rest_slot_set.remove('ticket')\n",
    "\n",
    "        if len(request_slot_set) > 0 or len(rest_slot_set) > 0:\n",
    "            self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "\n",
    "        for info_slot in self.state['hist_slots'].keys():\n",
    "            if self.state['hist_slots'][info_slot] == NlgConfig.NO_VALUE_MATCH:\n",
    "                self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "            if info_slot in self.goal['inform_slots'].keys():\n",
    "                if self.state['hist_slots'][info_slot] != self.goal['inform_slots'][info_slot]:\n",
    "                    self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "\n",
    "        if 'ticket' in system_action['inform_slots'].keys():\n",
    "            if system_action['inform_slots']['ticket'] == DlgManagerConfig.NO_VALUE_MATCH:\n",
    "                self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "                \n",
    "        if self.constraint_check == DlgManagerConfig.CONSTRAINT_CHECK_FAILURE:\n",
    "            self.dialog_status = DlgManagerConfig.FAILED_DIALOG\n",
    "    \n",
    "    def response_request(self, system_action):\n",
    "        \"\"\" Response for Request (System Action) \"\"\"\n",
    "        \n",
    "        if len(system_action['request_slots'].keys()) > 0:\n",
    "            slot = list(system_action['request_slots'].keys())[0] # only one slot\n",
    "            if slot in self.goal['inform_slots'].keys(): # request slot in user's constraints  #and slot not in self.state['request_slots'].keys():\n",
    "                self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "                self.state['diaact'] = \"inform\"\n",
    "                if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                if slot in self.state['request_slots'].keys(): del self.state['request_slots'][slot]\n",
    "                self.state['request_slots'].clear()\n",
    "            elif slot in self.goal['request_slots'].keys() and slot not in self.state['rest_slots'] and slot in self.state['hist_slots'].keys(): # the requested slot has been answered\n",
    "                self.state['inform_slots'][slot] = self.state['hist_slots'][slot]\n",
    "                self.state['request_slots'].clear()\n",
    "                self.state['diaact'] = \"inform\"\n",
    "            elif slot in self.goal['request_slots'].keys() and slot in self.state['rest_slots']: # request slot in user's goal's request slots, and not answered yet\n",
    "                self.state['diaact'] = \"request\" # \"confirm_question\"\n",
    "                self.state['request_slots'][slot] = \"UNK\"\n",
    "\n",
    "                ########################################################################\n",
    "                # Inform the rest of informable slots\n",
    "                ########################################################################\n",
    "                for info_slot in self.state['rest_slots']:\n",
    "                    if info_slot in self.goal['inform_slots'].keys():\n",
    "                        self.state['inform_slots'][info_slot] = self.goal['inform_slots'][info_slot]\n",
    "\n",
    "                for info_slot in self.state['inform_slots'].keys():\n",
    "                    if info_slot in self.state['rest_slots']:\n",
    "                        self.state['rest_slots'].remove(info_slot)\n",
    "            else:\n",
    "                if len(self.state['request_slots']) == 0 and len(self.state['rest_slots']) == 0:\n",
    "                    self.state['diaact'] = \"thanks\"\n",
    "                else:\n",
    "                    self.state['diaact'] = \"inform\"\n",
    "                self.state['inform_slots'][slot] = NlgConfig.I_DO_NOT_CARE\n",
    "        else: # this case should not appear\n",
    "            if len(self.state['rest_slots']) > 0:\n",
    "                random_slot = random.choice(self.state['rest_slots'])\n",
    "                if random_slot in self.goal['inform_slots'].keys():\n",
    "                    self.state['inform_slots'][random_slot] = self.goal['inform_slots'][random_slot]\n",
    "                    self.state['rest_slots'].remove(random_slot)\n",
    "                    self.state['diaact'] = \"inform\"\n",
    "                elif random_slot in self.goal['request_slots'].keys():\n",
    "                    self.state['request_slots'][random_slot] = self.goal['request_slots'][random_slot]\n",
    "                    self.state['diaact'] = \"request\"\n",
    "\n",
    "    def response_multiple_choice(self, system_action):\n",
    "        \"\"\" Response for Multiple_Choice (System Action) \"\"\"\n",
    "        \n",
    "        slot = system_action['inform_slots'].keys()[0]\n",
    "        if slot in self.goal['inform_slots'].keys():\n",
    "            self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "        elif slot in self.goal['request_slots'].keys():\n",
    "            self.state['inform_slots'][slot] = random.choice(system_action['inform_slots'][slot])\n",
    "\n",
    "        self.state['diaact'] = \"inform\"\n",
    "        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "        if slot in self.state['request_slots'].keys(): del self.state['request_slots'][slot]\n",
    "        \n",
    "    def response_inform(self, system_action):\n",
    "        \"\"\" Response for Inform (System Action) \"\"\"\n",
    "        \n",
    "        if 'taskcomplete' in system_action['inform_slots'].keys(): # check all the constraints from agents with user goal\n",
    "            self.state['diaact'] = \"thanks\"\n",
    "            #if 'ticket' in self.state['rest_slots']: self.state['request_slots']['ticket'] = 'UNK'\n",
    "            self.constraint_check = UserConfig.CONSTRAINT_CHECK_SUCCESS\n",
    "                    \n",
    "            if system_action['inform_slots']['taskcomplete'] == NlgConfig.NO_VALUE_MATCH:\n",
    "                self.state['hist_slots']['ticket'] = NlgConfig.NO_VALUE_MATCH\n",
    "                if 'ticket' in self.state['rest_slots']: self.state['rest_slots'].remove('ticket')\n",
    "                if 'ticket' in self.state['request_slots'].keys(): del self.state['request_slots']['ticket']\n",
    "                    \n",
    "            for slot in self.goal['inform_slots'].keys():\n",
    "                #  Deny, if the answers from agent can not meet the constraints of user\n",
    "                if slot not in system_action['inform_slots'].keys() or (self.goal['inform_slots'][slot].lower() != system_action['inform_slots'][slot].lower()):\n",
    "                    self.state['diaact'] = \"deny\"\n",
    "                    self.state['request_slots'].clear()\n",
    "                    self.state['inform_slots'].clear()\n",
    "                    self.constraint_check = UserConfig.CONSTRAINT_CHECK_FAILURE\n",
    "                    break\n",
    "        else:\n",
    "            for slot in system_action['inform_slots'].keys():\n",
    "                self.state['hist_slots'][slot] = system_action['inform_slots'][slot]\n",
    "                        \n",
    "                if slot in self.goal['inform_slots'].keys():\n",
    "                    if system_action['inform_slots'][slot] == self.goal['inform_slots'][slot]:\n",
    "                        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                                \n",
    "                        if len(self.state['request_slots']) > 0:\n",
    "                            self.state['diaact'] = \"request\"\n",
    "                        elif len(self.state['rest_slots']) > 0:\n",
    "                            rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "                            if 'ticket' in rest_slot_set:\n",
    "                                rest_slot_set.remove('ticket')\n",
    "\n",
    "                            if len(rest_slot_set) > 0:\n",
    "                                inform_slot = random.choice(rest_slot_set) # self.state['rest_slots']\n",
    "                                if inform_slot in self.goal['inform_slots'].keys():\n",
    "                                    self.state['inform_slots'][inform_slot] = self.goal['inform_slots'][inform_slot]\n",
    "                                    self.state['diaact'] = \"inform\"\n",
    "                                    self.state['rest_slots'].remove(inform_slot)\n",
    "                                elif inform_slot in self.goal['request_slots'].keys():\n",
    "                                    self.state['request_slots'][inform_slot] = 'UNK'\n",
    "                                    self.state['diaact'] = \"request\"\n",
    "                            else:\n",
    "                                self.state['request_slots']['ticket'] = 'UNK'\n",
    "                                self.state['diaact'] = \"request\"\n",
    "                        else: # how to reply here?\n",
    "                            self.state['diaact'] = \"thanks\" # replies \"closing\"? or replies \"confirm_answer\"\n",
    "                    else: # != value  Should we deny here or ?\n",
    "                        ########################################################################\n",
    "                        # TODO When agent informs(slot=value), where the value is different with the constraint in user goal, Should we deny or just inform the correct value?\n",
    "                        ########################################################################\n",
    "                        self.state['diaact'] = \"inform\"\n",
    "                        self.state['inform_slots'][slot] = self.goal['inform_slots'][slot]\n",
    "                        if slot in self.state['rest_slots']: self.state['rest_slots'].remove(slot)\n",
    "                else:\n",
    "                    if slot in self.state['rest_slots']:\n",
    "                        self.state['rest_slots'].remove(slot)\n",
    "                    if slot in self.state['request_slots'].keys():\n",
    "                        del self.state['request_slots'][slot]\n",
    "\n",
    "                    if len(self.state['request_slots']) > 0:\n",
    "                        request_set = list(self.state['request_slots'].keys())\n",
    "                        if 'ticket' in request_set:\n",
    "                            request_set.remove('ticket')\n",
    "\n",
    "                        if len(request_set) > 0:\n",
    "                            request_slot = random.choice(request_set)\n",
    "                        else:\n",
    "                            request_slot = 'ticket'\n",
    "\n",
    "                        self.state['request_slots'][request_slot] = \"UNK\"\n",
    "                        self.state['diaact'] = \"request\"\n",
    "                    elif len(self.state['rest_slots']) > 0:\n",
    "                        rest_slot_set = copy.deepcopy(self.state['rest_slots'])\n",
    "                        if 'ticket' in rest_slot_set:\n",
    "                            rest_slot_set.remove('ticket')\n",
    "\n",
    "                        if len(rest_slot_set) > 0:\n",
    "                            inform_slot = random.choice(rest_slot_set) #self.state['rest_slots']\n",
    "                            if inform_slot in self.goal['inform_slots'].keys():\n",
    "                                self.state['inform_slots'][inform_slot] = self.goal['inform_slots'][inform_slot]\n",
    "                                self.state['diaact'] = \"inform\"\n",
    "                                self.state['rest_slots'].remove(inform_slot)\n",
    "                                        \n",
    "                                if 'ticket' in self.state['rest_slots']:\n",
    "                                    self.state['request_slots']['ticket'] = 'UNK'\n",
    "                                    self.state['diaact'] = \"request\"\n",
    "                            elif inform_slot in self.goal['request_slots'].keys():\n",
    "                                self.state['request_slots'][inform_slot] = self.goal['request_slots'][inform_slot]\n",
    "                                self.state['diaact'] = \"request\"\n",
    "                        else:\n",
    "                            self.state['request_slots']['ticket'] = 'UNK'\n",
    "                            self.state['diaact'] = \"request\"\n",
    "                    else:\n",
    "                        self.state['diaact'] = \"thanks\" # or replies \"confirm_answer\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a movie dictionary for user simulator - slot:possible values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "keys = 20\n",
      "Sample of dict:\n",
      "- genre: ['comedy', 'comedies', 'kid', 'action', 'violence', 'superhero', 'romance', 'thriller', 'drama', 'family friendly', 'funny', 'kids', 'scary', 'horror', 'showing', 'romantic comedies', 'romantic comedy', 'adult comedy', 'romantic', 'drama/romance', 'foreign', 'superhero movie', 'dramas', 'animated', 'thriller science fiction', 'super great day', 'comedies)', 'not live action', 'date night:', 'sci-fi', 'Action/Adventure Sci-Fi/Fantasy']\n"
     ]
    }
   ],
   "source": [
    "movie_dict_path = './data/user/dicts.v3.p'\n",
    "movie_dictionary = pickle.load(open(movie_dict_path, 'rb'), encoding=\"latin\")\n",
    "samples = sample_dict(movie_dictionary, sample_size=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Create a User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "user = RuleSimulator(movie_dictionary, act_set, slot_set, goal_set, usersim_params)\n",
    "user.set_nlg_model(nlg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State Tracker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Knowledge Base Helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     2,
     61,
     152,
     162
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "class KBHelper:\n",
    "    \"\"\" \n",
    "    An assistant to fill in values for the agent (which knows about slots of values) \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, movie_dictionary):\n",
    "        self.movie_dictionary = movie_dictionary\n",
    "        self.cached_kb = defaultdict(list)\n",
    "        self.cached_kb_slot = defaultdict(list)\n",
    "\n",
    "\n",
    "    def fill_inform_slots(self, inform_slots_to_be_filled, current_slots):\n",
    "        \"\"\" \n",
    "        Takes unfilled inform slots and current_slots, returns dictionary of filled informed slots (with values)\n",
    "\n",
    "        Arguments:\n",
    "        inform_slots_to_be_filled   --  Something that looks like {starttime:None, theater:None} where starttime and theater are slots that the agent needs filled\n",
    "        current_slots               --  Contains a record of all filled slots in the conversation so far - for now, just use current_slots['inform_slots'] which is a dictionary of the already filled-in slots\n",
    "\n",
    "        Returns:\n",
    "        filled_in_slots             --  A dictionary of form {slot1:value1, slot2:value2} for each sloti in inform_slots_to_be_filled\n",
    "        \"\"\"\n",
    "        \n",
    "        kb_results = self.available_results_from_kb(current_slots)\n",
    "        if NlgConfig.auto_suggest == 1:\n",
    "            print('Number of movies in KB satisfying current constraints: ', len(kb_results))\n",
    "\n",
    "        filled_in_slots = {}\n",
    "        if 'taskcomplete' in inform_slots_to_be_filled.keys():\n",
    "            filled_in_slots.update(current_slots['inform_slots'])\n",
    "        \n",
    "        for slot in inform_slots_to_be_filled.keys():\n",
    "            if slot == 'numberofpeople':\n",
    "                if slot in current_slots['inform_slots'].keys():\n",
    "                    filled_in_slots[slot] = current_slots['inform_slots'][slot]\n",
    "                elif slot in inform_slots_to_be_filled.keys():\n",
    "                    filled_in_slots[slot] = inform_slots_to_be_filled[slot]\n",
    "                continue\n",
    "\n",
    "            if slot == 'ticket' or slot == 'taskcomplete':\n",
    "                filled_in_slots[slot] = NlgConfig.TICKET_AVAILABLE if len(kb_results)>0 else NlgConfig.NO_VALUE_MATCH\n",
    "                continue\n",
    "            \n",
    "            if slot == 'closing': continue\n",
    "\n",
    "            ####################################################################\n",
    "            #   Grab the value for the slot with the highest count and fill it\n",
    "            ####################################################################\n",
    "            values_dict = self.available_slot_values(slot, kb_results)\n",
    "\n",
    "            values_counts = [(v, values_dict[v]) for v in values_dict.keys()]\n",
    "            if len(values_counts) > 0:\n",
    "                filled_in_slots[slot] = sorted(values_counts, key = lambda x: -x[1])[0][0]\n",
    "            else:\n",
    "                filled_in_slots[slot] = NlgConfig.NO_VALUE_MATCH #\"NO VALUE MATCHES SNAFU!!!\"\n",
    "           \n",
    "        return filled_in_slots\n",
    "\n",
    "\n",
    "    def available_slot_values(self, slot, kb_results):\n",
    "        \"\"\" \n",
    "        Return the set of values available for the slot based on the current constraints \n",
    "        \"\"\"\n",
    "        \n",
    "        slot_values = {}\n",
    "        for movie_id in kb_results.keys():\n",
    "            if slot in kb_results[movie_id].keys():\n",
    "                slot_val = kb_results[movie_id][slot]\n",
    "                if slot_val in slot_values.keys():\n",
    "                    slot_values[slot_val] += 1\n",
    "                else: slot_values[slot_val] = 1\n",
    "        return slot_values\n",
    "\n",
    "    def available_results_from_kb(self, current_slots):\n",
    "        \"\"\" \n",
    "        Return the available movies in the movie_kb based on the current constraints \n",
    "        \"\"\"\n",
    "        \n",
    "        ret_result = []\n",
    "        current_slots = current_slots['inform_slots']\n",
    "        constrain_keys = current_slots.keys()\n",
    "\n",
    "        constrain_keys = filter(lambda k : k != 'ticket' and \\\n",
    "                                           k != 'numberofpeople' and \\\n",
    "                                           k!= 'taskcomplete' and \\\n",
    "                                           k != 'closing' , constrain_keys)\n",
    "        constrain_keys = [k for k in constrain_keys if current_slots[k] != NlgConfig.I_DO_NOT_CARE]\n",
    "\n",
    "        query_idx_keys = frozenset(current_slots.items())\n",
    "        cached_kb_ret = self.cached_kb[query_idx_keys]\n",
    "\n",
    "        cached_kb_length = len(cached_kb_ret) if cached_kb_ret != None else -1\n",
    "        if cached_kb_length > 0:\n",
    "            return dict(cached_kb_ret)\n",
    "        elif cached_kb_length == -1:\n",
    "            return dict([])\n",
    "\n",
    "        # kb_results = copy.deepcopy(self.movie_dictionary)\n",
    "        for id in self.movie_dictionary.keys():\n",
    "            kb_keys = self.movie_dictionary[id].keys()\n",
    "            if len(set(constrain_keys).union(set(kb_keys)) ^ (set(constrain_keys) ^ set(kb_keys))) == len(\n",
    "                    constrain_keys):\n",
    "                match = True\n",
    "                for idx, k in enumerate(constrain_keys):\n",
    "                    if str(current_slots[k]).lower() == str(self.movie_dictionary[id][k]).lower():\n",
    "                        continue\n",
    "                    else:\n",
    "                        match = False\n",
    "                if match:\n",
    "                    self.cached_kb[query_idx_keys].append((id, self.movie_dictionary[id]))\n",
    "                    ret_result.append((id, self.movie_dictionary[id]))\n",
    "        if len(ret_result) == 0:\n",
    "            self.cached_kb[query_idx_keys] = None\n",
    "\n",
    "        ret_result = dict(ret_result)\n",
    "        return ret_result\n",
    "    \n",
    "    def available_results_from_kb_for_slots(self, inform_slots):\n",
    "        \"\"\" \n",
    "        Return the count statistics for each constraint in inform_slots \n",
    "        \"\"\"\n",
    "        \n",
    "        kb_results = {key:0 for key in inform_slots.keys()}\n",
    "        kb_results['matching_all_constraints'] = 0\n",
    "        \n",
    "        query_idx_keys = frozenset(inform_slots.items())\n",
    "        cached_kb_slot_ret = self.cached_kb_slot[query_idx_keys]\n",
    "\n",
    "        if len(cached_kb_slot_ret) > 0:\n",
    "            return cached_kb_slot_ret[0]\n",
    "\n",
    "        for movie_id in self.movie_dictionary.keys():\n",
    "            all_slots_match = 1\n",
    "            for slot in inform_slots.keys():\n",
    "                if slot == 'ticket' or inform_slots[slot] == NlgConfig.I_DO_NOT_CARE:\n",
    "                    continue\n",
    "\n",
    "                if slot in self.movie_dictionary[movie_id].keys():\n",
    "                    if inform_slots[slot].lower() == self.movie_dictionary[movie_id][slot].lower():\n",
    "                        kb_results[slot] += 1\n",
    "                    else:\n",
    "                        all_slots_match = 0\n",
    "                else:\n",
    "                    all_slots_match = 0\n",
    "            kb_results['matching_all_constraints'] += all_slots_match\n",
    "\n",
    "        self.cached_kb_slot[query_idx_keys].append(kb_results)\n",
    "        return kb_results\n",
    "\n",
    "    \n",
    "    def database_results_for_agent(self, current_slots):\n",
    "        \"\"\" \n",
    "        A dictionary of the number of results matching each current constraint. \n",
    "        The agent needs this to decide what to do next. \n",
    "        \"\"\"\n",
    "\n",
    "        database_results ={} # { date:100, distanceconstraints:60, theater:30,  matching_all_constraints: 5}\n",
    "        database_results = self.available_results_from_kb_for_slots(current_slots['inform_slots'])\n",
    "        return database_results\n",
    "    \n",
    "    def suggest_slot_values(self, request_slots, current_slots):\n",
    "        \"\"\" \n",
    "        Return the suggest slot values \n",
    "        \"\"\"\n",
    "        \n",
    "        avail_kb_results = self.available_results_from_kb(current_slots)\n",
    "        return_suggest_slot_vals = {}\n",
    "        for slot in request_slots.keys():\n",
    "            avail_values_dict = self.available_slot_values(slot, avail_kb_results)\n",
    "            values_counts = [(v, avail_values_dict[v]) for v in avail_values_dict.keys()]\n",
    "            \n",
    "            if len(values_counts) > 0:\n",
    "                return_suggest_slot_vals[slot] = []\n",
    "                sorted_dict = sorted(values_counts, key = lambda x: -x[1])\n",
    "                for k in sorted_dict: return_suggest_slot_vals[slot].append(k[0])\n",
    "            else:\n",
    "                return_suggest_slot_vals[slot] = []\n",
    "        \n",
    "        return return_suggest_slot_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class StateTracker:\n",
    "    \"\"\" \n",
    "    The state tracker maintains a record of which request slots are filled and which inform slots are filled \n",
    "    \"\"\"\n",
    "    def __init__(self, act_set, slot_set, movie_dictionary):\n",
    "        self.act_set = act_set\n",
    "        self.movie_dictionary = movie_dictionary\n",
    "        self.slot_set = slot_set\n",
    "        self.slot_set = slot_set\n",
    "        self.hist_dic = None\n",
    "        self.curr_slots = None\n",
    "        self.init_episode()\n",
    "        self.act_dim = 10\n",
    "        self.kb_result_dim = 10\n",
    "        self.turn_count = 0\n",
    "        self.kb_helper = KBHelper(movie_dictionary)\n",
    "    \n",
    "    def init_episode(self):\n",
    "        \"\"\" \n",
    "        Initialize a new episode (dialog), flush the current state and tracked slots \n",
    "        \"\"\"\n",
    "        self.act_dim = 10\n",
    "        self.hist_vectors = np.zeros(self.act_dim)\n",
    "        self.hist_dic = []\n",
    "        self.turn_count = 0\n",
    "        self.curr_slots = {}\n",
    "        self.curr_slots['inform_slots'] = {}\n",
    "        self.curr_slots['request_slots'] = {}\n",
    "        self.curr_slots['proposed_slots'] = {}\n",
    "        self.curr_slots['agt_request_slots'] = {}\n",
    "    \n",
    "    def get_state_for_agent(self):\n",
    "        \"\"\" \n",
    "        Get the state representatons to send to agent \n",
    "        state = \n",
    "            {'user_action': self.hist_dic[-1], \n",
    "             'curr_slots': self.curr_slots, \n",
    "             'kb_results': self.kb_results_for_state()}\n",
    "        \"\"\"\n",
    "        state = {\n",
    "            \"user_action\": self.hist_dic[-1],\n",
    "            \"curr_slots\":  self.curr_slots,\n",
    "            \"kb_results\":  self.kb_helper.database_results_for_agent(self.curr_slots),\n",
    "            'turn': self.turn_count, \n",
    "            'history': self.hist_dic, \n",
    "            'agent_action': self.hist_dic[-2] if len(self.hist_dic) > 1 else None\n",
    "        }\n",
    "        return copy.deepcopy(state)\n",
    "    \n",
    "    def dialog_history_vectors(self):\n",
    "        \"\"\" Return the dialog history (both user and agent actions) in vector representation \"\"\"\n",
    "        return self.hist_vec\n",
    "\n",
    "    def dialog_history_dictionaries(self):\n",
    "        \"\"\"  Return the dictionary representation of the dialog history (includes values) \"\"\"\n",
    "        return self.hist_dic\n",
    "    \n",
    "    \n",
    "    def update(self, agent_action=None, user_action=None):\n",
    "        \"\"\" \n",
    "        Update the state based on the latest action \n",
    "        \"\"\"\n",
    "\n",
    "        ########################################################################\n",
    "        #  Make sure that the function was called properly\n",
    "        ########################################################################\n",
    "        assert(not (user_action and agent_action))\n",
    "        assert(user_action or agent_action)\n",
    "\n",
    "        ########################################################################\n",
    "        #   Update state to reflect a new action by the agent.\n",
    "        ########################################################################\n",
    "        if agent_action:\n",
    "            \n",
    "            ####################################################################\n",
    "            #   Handles the act_slot response (with values needing to be filled)\n",
    "            ####################################################################\n",
    "            if agent_action['act_slot_response']:\n",
    "                response = copy.deepcopy(agent_action['act_slot_response'])\n",
    "                \n",
    "                inform_slots = self.kb_helper.fill_inform_slots(response['inform_slots'], self.curr_slots) # TODO this doesn't actually work yet, remove this warning when kb_helper is functional\n",
    "                agent_action_values = {'turn': self.turn_count, 'speaker': \"agent\", 'diaact': response['diaact'], 'inform_slots': inform_slots, 'request_slots':response['request_slots']}\n",
    "                \n",
    "                agent_action['act_slot_response'].update({'diaact': response['diaact'], 'inform_slots': inform_slots, 'request_slots':response['request_slots'], 'turn':self.turn_count})\n",
    "                \n",
    "            elif agent_action['act_slot_value_response']:\n",
    "                agent_action_values = copy.deepcopy(agent_action['act_slot_value_response'])\n",
    "                # print(\"Updating state based on act_slot_value action from agent\")\n",
    "                agent_action_values['turn'] = self.turn_count\n",
    "                agent_action_values['speaker'] = \"agent\"\n",
    "                \n",
    "            ####################################################################\n",
    "            #   This code should execute regardless of which kind of agent produced action\n",
    "            ####################################################################\n",
    "            for slot in agent_action_values['inform_slots'].keys():\n",
    "                self.curr_slots['proposed_slots'][slot] = agent_action_values['inform_slots'][slot]\n",
    "                self.curr_slots['inform_slots'][slot] = agent_action_values['inform_slots'][slot] # add into inform_slots\n",
    "                if slot in self.curr_slots['request_slots'].keys():\n",
    "                    del self.curr_slots['request_slots'][slot]\n",
    "\n",
    "            for slot in agent_action_values['request_slots'].keys():\n",
    "                if slot not in self.curr_slots['agt_request_slots']:\n",
    "                    self.curr_slots['agt_request_slots'][slot] = \"UNK\"\n",
    "\n",
    "            self.hist_dic.append(agent_action_values)\n",
    "            current_agent_vector = np.ones((1, self.act_dim))\n",
    "            self.hist_vectors = np.vstack([self.hist_vectors, current_agent_vector])\n",
    "                            \n",
    "        ########################################################################\n",
    "        #   Update the state to reflect a new action by the user\n",
    "        ########################################################################\n",
    "        elif user_action:\n",
    "            \n",
    "            ####################################################################\n",
    "            #   Update the current slots\n",
    "            ####################################################################\n",
    "            for slot in user_action['inform_slots'].keys():\n",
    "                self.curr_slots['inform_slots'][slot] = user_action['inform_slots'][slot]\n",
    "                if slot in self.curr_slots['request_slots'].keys():\n",
    "                    del self.curr_slots['request_slots'][slot]\n",
    "\n",
    "            for slot in user_action['request_slots'].keys():\n",
    "                if slot not in self.curr_slots['request_slots']:\n",
    "                    self.curr_slots['request_slots'][slot] = \"UNK\"\n",
    "            \n",
    "            self.hist_vectors = np.vstack([self.hist_vectors, np.zeros((1,self.act_dim))])\n",
    "            new_move = {'turn': self.turn_count, 'speaker': \"user\", 'request_slots': user_action['request_slots'], 'inform_slots': user_action['inform_slots'], 'diaact': user_action['diaact']}\n",
    "            self.hist_dic.append(copy.deepcopy(new_move))\n",
    "\n",
    "        ########################################################################\n",
    "        #   This should never happen if the asserts passed\n",
    "        ########################################################################\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        ########################################################################\n",
    "        #   This code should execute after update code regardless of what kind of action (agent/user)\n",
    "        ########################################################################\n",
    "        self.turn_count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pretrained model path = None\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "agent_params = {}\n",
    "# maximum length of each dialog (default=20, 0=no maximum length)\n",
    "agent_params['max_turn'] = 20\n",
    "# Epsilon to determine stochasticity of epsilon-greedy agent policies\n",
    "agent_params['epsilon'] = 0\n",
    "# run_mode: 0 for default NL; 1 for dia_act; 2 for both\n",
    "agent_params['agent_run_mode'] = 0\n",
    "# 0 for dia_act level; 1 for NL level\n",
    "agent_params['agent_act_level'] = 0\n",
    "\n",
    "############### DQN #################\n",
    "# the size for experience replay\n",
    "agent_params['experience_replay_pool_size'] = 1000\n",
    "# # the hidden size for DQN\n",
    "agent_params['dqn_hidden_size'] = 60\n",
    "agent_params['batch_size'] = 16\n",
    "# # gamma for DQN\n",
    "agent_params['gamma'] = 0.9\n",
    "# # predict model for DQN\n",
    "agent_params['predict_mode'] = False\n",
    "agent_params['trained_model_path'] = params['pretrained_model_path']\n",
    "#####################################\n",
    "print(\"pretrained model path = {}\".format(agent_params['trained_model_path']))\n",
    "# 0: no warm start; 1: warm start for training\n",
    "agent_params['warm_start'] = 1\n",
    "# run_mode: 0 for NL; 1 for dia_act\n",
    "agent_params['cmd_input_mode'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \"\"\" \n",
    "    Parent for all agent classes, defining the interface they must uphold \n",
    "    \"\"\"\n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, params=None):\n",
    "        \"\"\" \n",
    "        movie_dict      --  This is here now but doesn't belong - the agent doesn't know about movies\n",
    "        act_set         --  The set of acts. #### Shouldn't this be more abstract? Don't we want our agent to be more broadly usable?\n",
    "        slot_set        --  The set of available slots\n",
    "        \"\"\"\n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.act_cardinality = len(act_set.keys())\n",
    "        self.slot_cardinality = len(slot_set.keys())\n",
    "        \n",
    "        self.epsilon = params['epsilon']\n",
    "        self.agent_run_mode = params['agent_run_mode']\n",
    "        self.agent_act_level = params['agent_act_level']\n",
    "    \n",
    "    def init_episode(self):\n",
    "        \"\"\" \n",
    "        Initialize a new episode. \n",
    "        This function is called every time a new episode is run. \n",
    "        \"\"\"\n",
    "        self.current_action = {}                    #   TODO Changed this variable's name to current_action\n",
    "        self.current_action['diaact'] = None        #   TODO Does it make sense to call it a state if it has an act? Which act? The Most recent?\n",
    "        self.current_action['inform_slots'] = {}\n",
    "        self.current_action['request_slots'] = {}\n",
    "        \n",
    "        self.current_action['turn'] = 0\n",
    "    \n",
    "    def set_nlg_model(self, nlg_model):\n",
    "        self.nlg_model = nlg_model  \n",
    "    \n",
    "    def set_nlu_model(self, nlu_model):\n",
    "        self.nlu_model = nlu_model\n",
    "    \n",
    "    def register_experience_replay_tuple(self, s_t, a_t, reward, s_tplus1, episode_over):\n",
    "        \"\"\"  Register feedback from the environment, to be stored as future training data\n",
    "\n",
    "        Arguments:\n",
    "        s_t                 --  The state in which the last action was taken\n",
    "        a_t                 --  The previous agent action\n",
    "        reward              --  The reward received immediately following the action\n",
    "        s_tplus1            --  The state transition following the latest action\n",
    "        episode_over        --  A boolean value representing whether the this is the final action.\n",
    "\n",
    "        Returns:\n",
    "        None\n",
    "        \"\"\"\n",
    "        pass\n",
    "        \n",
    "    def state_to_action(self, state, available_actions):\n",
    "        \"\"\" \n",
    "        Take the current state and return an action according to the current exploration/exploitation policy\n",
    "\n",
    "        We define the agents flexibly so that they can either operate on act_slot representations or act_slot_value representations.\n",
    "        We also define the responses flexibly, returning a dictionary with keys [act_slot_response, act_slot_value_response]. This way the command-line agent can continue to operate with values\n",
    "\n",
    "        Arguments:\n",
    "        state      --   A tuple of (history, kb_results) where history is a sequence of previous actions and kb_results contains information on the number of results matching the current constraints.\n",
    "        user_action         --   A legacy representation used to run the command line agent. We should remove this ASAP but not just yet\n",
    "        available_actions   --   A list of the allowable actions in the current state\n",
    "\n",
    "        Returns:\n",
    "        act_slot_action         --   An action consisting of one act and >= 0 slots as well as which slots are informed vs requested.\n",
    "        act_slot_value_action   --   An action consisting of acts slots and values in the legacy format. This can be used in the future for training agents that take value into account and interact directly with the database\n",
    "        \"\"\"\n",
    "        print(\"Agent state_to_action\")\n",
    "        act_slot_response = None\n",
    "        act_slot_value_response = None\n",
    "        return({\"act_slot_response\": act_slot_response, \"act_slot_value_response\": act_slot_value_response})\n",
    "    \n",
    "    def add_nl_to_action(self, agent_action):\n",
    "        \"\"\" Add NL to Agent Dia_Act \"\"\"\n",
    "        \n",
    "        if agent_action['act_slot_response']:\n",
    "            agent_action['act_slot_response']['nl'] = \"\"\n",
    "            user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(agent_action['act_slot_response'], 'agt') #self.nlg_model.translate_diaact(agent_action['act_slot_response']) # NLG\n",
    "            agent_action['act_slot_response']['nl'] = user_nlg_sentence\n",
    "        elif agent_action['act_slot_value_response']:\n",
    "            agent_action['act_slot_value_response']['nl'] = \"\"\n",
    "            user_nlg_sentence = self.nlg_model.convert_diaact_to_nl(agent_action['act_slot_value_response'], 'agt') #self.nlg_model.translate_diaact(agent_action['act_slot_value_response']) # NLG\n",
    "            agent_action['act_slot_response']['nl'] = user_nlg_sentenc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Request Basics Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class RequestBasicsAgent(Agent):\n",
    "    \"\"\" \n",
    "    A simple agent to test the system. \n",
    "    This agent should simply request all the basic slots and then issue: thanks(). \n",
    "    \"\"\"\n",
    "    def init_episode(self):\n",
    "        self.state = {}\n",
    "        self.state['diaact'] = 'UNK'\n",
    "        self.state['inform_slots'] = {}\n",
    "        self.state['request_slots'] = {}\n",
    "        self.state['turn'] = -1\n",
    "        self.current_slot_id = 0\n",
    "        self.request_set = ['moviename', 'starttime', 'city', 'date', 'theater', 'numberofpeople']\n",
    "        self.phase = 0\n",
    "\n",
    "    def state_to_action(self, state):\n",
    "        \"\"\" Run current policy on state and produce an action \"\"\"\n",
    "        self.state['turn'] += 2\n",
    "        if self.current_slot_id < len(self.request_set):\n",
    "            slot = self.request_set[self.current_slot_id]\n",
    "            self.current_slot_id += 1\n",
    "\n",
    "            act_slot_response = {}\n",
    "            act_slot_response['diaact'] = \"request\"\n",
    "            act_slot_response['inform_slots'] = {}\n",
    "            act_slot_response['request_slots'] = {slot: \"UNK\"}\n",
    "            act_slot_response['turn'] = self.state['turn']\n",
    "        elif self.phase == 0:\n",
    "            act_slot_response = {'diaact': \"inform\", 'inform_slots': {'taskcomplete': \"PLACEHOLDER\"}, 'request_slots': {}, 'turn':self.state['turn']}\n",
    "            self.phase += 1\n",
    "        elif self.phase == 1:\n",
    "            act_slot_response = {'diaact': \"thanks\", 'inform_slots': {}, 'request_slots': {}, 'turn': self.state['turn']}\n",
    "        else:\n",
    "            raise Exception(\"THIS SHOULD NOT BE POSSIBLE (AGENT CALLED IN UNANTICIPATED WAY)\")\n",
    "        return {'act_slot_response': act_slot_response, 'act_slot_value_response': None}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN Alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "code_folding": [
     23,
     66,
     105,
     122,
     145,
     158,
     221
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DQN:\n",
    "    \n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        self.model = {}\n",
    "        # input-hidden\n",
    "        self.model['Wxh'] = initWeight(input_size, hidden_size)\n",
    "        self.model['bxh'] = np.zeros((1, hidden_size))\n",
    "      \n",
    "        # hidden-output\n",
    "        self.model['Wd'] = initWeight(hidden_size, output_size)*0.1\n",
    "        self.model['bd'] = np.zeros((1, output_size))\n",
    "\n",
    "        self.update = ['Wxh', 'bxh', 'Wd', 'bd']\n",
    "        self.regularize = ['Wxh', 'Wd']\n",
    "\n",
    "        self.step_cache = {}\n",
    "        \n",
    "\n",
    "    def getStruct(self):\n",
    "        return {'model': self.model, 'update': self.update, 'regularize': self.regularize}\n",
    "    \n",
    "    \n",
    "    \"\"\"Activation Function: Sigmoid, or tanh, or ReLu\"\"\"\n",
    "    def fwdPass(self, Xs, params, **kwargs):\n",
    "        predict_mode = kwargs.get('predict_mode', False)\n",
    "        active_func = params.get('activation_func', 'relu')\n",
    " \n",
    "        # input layer to hidden layer\n",
    "        Wxh = self.model['Wxh']\n",
    "        bxh = self.model['bxh']\n",
    "        Xsh = Xs.dot(Wxh) + bxh\n",
    "        \n",
    "        hidden_size = self.model['Wd'].shape[0] # size of hidden layer\n",
    "        H = np.zeros((1, hidden_size)) # hidden layer representation\n",
    "        \n",
    "        if active_func == 'sigmoid':\n",
    "            H = 1/(1+np.exp(-Xsh))\n",
    "        elif active_func == 'tanh':\n",
    "            H = np.tanh(Xsh)\n",
    "        elif active_func == 'relu': # ReLU \n",
    "            H = np.maximum(Xsh, 0)\n",
    "        else: # no activation function\n",
    "            H = Xsh\n",
    "                \n",
    "        # decoder at the end; hidden layer to output layer\n",
    "        Wd = self.model['Wd']\n",
    "        bd = self.model['bd']\n",
    "        Y = H.dot(Wd) + bd\n",
    "        \n",
    "        # cache the values in forward pass, we expect to do a backward pass\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['Wxh'] = Wxh\n",
    "            cache['Wd'] = Wd\n",
    "            cache['Xs'] = Xs\n",
    "            cache['Xsh'] = Xsh\n",
    "            cache['H'] = H\n",
    "            \n",
    "            cache['bxh'] = bxh\n",
    "            cache['bd'] = bd\n",
    "            cache['activation_func'] = active_func\n",
    "            \n",
    "            cache['Y'] = Y\n",
    "            \n",
    "        return Y, cache\n",
    "    \n",
    "    def bwdPass(self, dY, cache):\n",
    "        Wd = cache['Wd']\n",
    "        H = cache['H']\n",
    "        Xs = cache['Xs']\n",
    "        Xsh = cache['Xsh']\n",
    "        Wxh = cache['Wxh']\n",
    " \n",
    "        active_func = cache['activation_func']\n",
    "        n,d = H.shape\n",
    "        \n",
    "        dH = dY.dot(Wd.transpose())\n",
    "        # backprop the decoder\n",
    "        dWd = H.transpose().dot(dY)\n",
    "        dbd = np.sum(dY, axis=0, keepdims=True)\n",
    "        \n",
    "        dXsh = np.zeros(Xsh.shape)\n",
    "        dXs = np.zeros(Xs.shape)\n",
    "        \n",
    "        if active_func == 'sigmoid':\n",
    "            dH = (H-H**2)*dH\n",
    "        elif active_func == 'tanh':\n",
    "            dH = (1-H**2)*dH\n",
    "        elif active_func == 'relu':\n",
    "            dH = (H>0)*dH # backprop ReLU\n",
    "        else:\n",
    "            dH = dH\n",
    "              \n",
    "        # backprop to the input-hidden connection\n",
    "        dWxh = Xs.transpose().dot(dH)\n",
    "        dbxh = np.sum(dH, axis=0, keepdims = True)\n",
    "        \n",
    "        # backprop to the input\n",
    "        dXsh = dH\n",
    "        dXs = dXsh.dot(Wxh.transpose())\n",
    "        \n",
    "        return {'Wd': dWd, 'bd': dbd, 'Wxh':dWxh, 'bxh':dbxh}\n",
    "    \n",
    "    \n",
    "    \"\"\"batch Forward & Backward Pass\"\"\"\n",
    "    def batchForward(self, batch, params, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Xs = np.array([x['cur_states']], dtype=float)\n",
    "            \n",
    "            Y, out_cache = self.fwdPass(Xs, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "           \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache\n",
    "    \n",
    "    def batchDoubleForward(self, batch, params, clone_dqn, predict_mode = False):\n",
    "        caches = []\n",
    "        Ys = []\n",
    "        tYs = []\n",
    "        \n",
    "        for i,x in enumerate(batch):\n",
    "            Xs = x[0]\n",
    "            Y, out_cache = self.fwdPass(Xs, params, predict_mode = predict_mode)\n",
    "            caches.append(out_cache)\n",
    "            Ys.append(Y)\n",
    "            \n",
    "            tXs = x[3]\n",
    "            tY, t_cache = clone_dqn.fwdPass(tXs, params, predict_mode = False)\n",
    "                \n",
    "            tYs.append(tY)\n",
    "            \n",
    "        # back up information for efficient backprop\n",
    "        cache = {}\n",
    "        if not predict_mode:\n",
    "            cache['caches'] = caches\n",
    "\n",
    "        return Ys, cache, tYs\n",
    "    \n",
    "    def batchBackward(self, dY, cache):\n",
    "        caches = cache['caches']\n",
    "        \n",
    "        grads = {}\n",
    "        for i in xrange(len(caches)):\n",
    "            single_cache = caches[i]\n",
    "            local_grads = self.bwdPass(dY[i], single_cache)\n",
    "            mergeDicts(grads, local_grads) # add up the gradients wrt model parameters\n",
    "            \n",
    "        return grads\n",
    "\n",
    "\n",
    "    \"\"\" cost function, returns cost and gradients for model \"\"\"\n",
    "    def costFunc(self, batch, params, clone_dqn):\n",
    "        regc = params.get('reg_cost', 1e-3)\n",
    "        gamma = params.get('gamma', 0.9)\n",
    "        \n",
    "        # batch forward\n",
    "        Ys, caches, tYs = self.batchDoubleForward(batch, params, clone_dqn, predict_mode = False)\n",
    "        \n",
    "        loss_cost = 0.0\n",
    "        dYs = []\n",
    "        for i,x in enumerate(batch):\n",
    "            Y = Ys[i]\n",
    "            nY = tYs[i]\n",
    "            \n",
    "            action = np.array(x[1], dtype=int)\n",
    "            reward = np.array(x[2], dtype=float)\n",
    "            \n",
    "            n_action = np.nanargmax(nY[0])\n",
    "            max_next_y = nY[0][n_action]\n",
    "            \n",
    "            eposide_terminate = x[4]\n",
    "            \n",
    "            target_y = reward\n",
    "            if eposide_terminate != True: target_y += gamma*max_next_y\n",
    "            \n",
    "            pred_y = Y[0][action]\n",
    "            \n",
    "            nY = np.zeros(nY.shape)\n",
    "            nY[0][action] = target_y\n",
    "            Y = np.zeros(Y.shape)\n",
    "            Y[0][action] = pred_y\n",
    "            \n",
    "            # Cost Function\n",
    "            loss_cost += (target_y - pred_y)**2\n",
    "                \n",
    "            dY = -(nY - Y)\n",
    "            #dY = np.minimum(dY, 1)\n",
    "            #dY = np.maximum(dY, -1)\n",
    "            dYs.append(dY)\n",
    "        \n",
    "        # backprop the RNN\n",
    "        grads = self.batchBackward(dYs, caches)\n",
    "        \n",
    "        # add L2 regularization cost and gradients\n",
    "        reg_cost = 0.0\n",
    "        if regc > 0:    \n",
    "            for p in self.regularize:\n",
    "                mat = self.model[p]\n",
    "                reg_cost += 0.5*regc*np.sum(mat*mat)\n",
    "                grads[p] += regc*mat\n",
    "\n",
    "        # normalize the cost and gradient by the batch size\n",
    "        batch_size = len(batch)\n",
    "        reg_cost /= batch_size\n",
    "        loss_cost /= batch_size\n",
    "        for k in grads: grads[k] /= batch_size\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = {'reg_cost' : reg_cost, 'loss_cost' : loss_cost, 'total_cost' : loss_cost + reg_cost}\n",
    "        out['grads'] = grads\n",
    "        return out\n",
    "\n",
    "\n",
    "    \"\"\" A single batch \"\"\"\n",
    "    def singleBatch(self, batch, params, clone_dqn):\n",
    "        learning_rate = params.get('learning_rate', 0.001)\n",
    "        decay_rate = params.get('decay_rate', 0.999)\n",
    "        momentum = params.get('momentum', 0.1)\n",
    "        grad_clip = params.get('grad_clip', -1e-3)\n",
    "        smooth_eps = params.get('smooth_eps', 1e-8)\n",
    "        sdg_type = params.get('sdgtype', 'rmsprop')\n",
    "        activation_func = params.get('activation_func', 'relu')\n",
    "        \n",
    "        for u in self.update:\n",
    "            if not u in self.step_cache: \n",
    "                self.step_cache[u] = np.zeros(self.model[u].shape)\n",
    "        \n",
    "        cg = self.costFunc(batch, params, clone_dqn)\n",
    "        \n",
    "        cost = cg['cost']\n",
    "        grads = cg['grads']\n",
    "        \n",
    "        # clip gradients if needed\n",
    "        if activation_func.lower() == 'relu':\n",
    "            if grad_clip > 0:\n",
    "                for p in self.update:\n",
    "                    if p in grads:\n",
    "                        grads[p] = np.minimum(grads[p], grad_clip)\n",
    "                        grads[p] = np.maximum(grads[p], -grad_clip)\n",
    "        \n",
    "        # perform parameter update\n",
    "        for p in self.update:\n",
    "            if p in grads:\n",
    "                if sdg_type == 'vanilla':\n",
    "                    if momentum > 0:\n",
    "                        dx = momentum*self.step_cache[p] - learning_rate*grads[p]\n",
    "                    else:\n",
    "                        dx = -learning_rate*grads[p]\n",
    "                    self.step_cache[p] = dx\n",
    "                elif sdg_type == 'rmsprop':\n",
    "                    self.step_cache[p] = self.step_cache[p]*decay_rate + (1.0-decay_rate)*grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                elif sdg_type == 'adgrad':\n",
    "                    self.step_cache[p] += grads[p]**2\n",
    "                    dx = -(learning_rate*grads[p])/np.sqrt(self.step_cache[p] + smooth_eps)\n",
    "                    \n",
    "                self.model[p] += dx\n",
    "\n",
    "        out = {}\n",
    "        out['cost'] = cost\n",
    "        return out\n",
    "    \n",
    "    \"\"\" prediction \"\"\"\n",
    "    def predict(self, Xs, params, **kwargs):\n",
    "        Ys, caches = self.fwdPass(Xs, params, predict_model=True)\n",
    "        pred_action = np.argmax(Ys)\n",
    "        \n",
    "        return pred_action\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DQN Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "code_folding": [
     46
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class AgentDQN(Agent):\n",
    "    def __init__(self, movie_dict=None, act_set=None, slot_set=None, params=None):\n",
    "        self.movie_dict = movie_dict\n",
    "        self.act_set = act_set\n",
    "        self.slot_set = slot_set\n",
    "        self.act_cardinality = len(act_set.keys())\n",
    "        self.slot_cardinality = len(slot_set.keys())\n",
    "        \n",
    "        self.feasible_actions = AgentConfig.feasible_actions\n",
    "        self.num_actions = len(self.feasible_actions)\n",
    "        \n",
    "        self.epsilon = params['epsilon']\n",
    "        self.agent_run_mode = params['agent_run_mode']\n",
    "        self.agent_act_level = params['agent_act_level']\n",
    "        self.experience_replay_pool = [] #experience replay pool <s_t, a_t, r_t, s_t+1>\n",
    "        \n",
    "        self.experience_replay_pool_size = params.get('experience_replay_pool_size', 1000)\n",
    "        self.hidden_size = params.get('dqn_hidden_size', 60)\n",
    "        self.gamma = params.get('gamma', 0.9)\n",
    "        self.predict_mode = params.get('predict_mode', False)\n",
    "        self.warm_start = params.get('warm_start', 0)\n",
    "        \n",
    "        self.max_turn = params['max_turn'] + 4\n",
    "        self.state_dimension = 2 * self.act_cardinality + 7 * self.slot_cardinality + 3 + self.max_turn\n",
    "        \n",
    "        self.dqn = DQN(self.state_dimension, self.hidden_size, self.num_actions)\n",
    "        self.clone_dqn = copy.deepcopy(self.dqn)\n",
    "        \n",
    "        self.cur_bellman_err = 0\n",
    "                \n",
    "        # Prediction Mode: load trained DQN model\n",
    "        if params['trained_model_path'] != None:\n",
    "            self.dqn.model = copy.deepcopy(self.load_trained_DQN(params['trained_model_path']))\n",
    "            self.clone_dqn = copy.deepcopy(self.dqn)\n",
    "            self.predict_mode = True\n",
    "            self.warm_start = 2\n",
    "            \n",
    "            \n",
    "    def init_episode(self):\n",
    "        \"\"\" Initialize a new episode. This function is called every time a new episode is run. \"\"\"\n",
    "        \n",
    "        self.current_slot_id = 0\n",
    "        self.phase = 0\n",
    "        self.request_set = ['moviename', 'starttime', 'city', 'date', 'theater', 'numberofpeople']\n",
    "    \n",
    "    \n",
    "    def state_to_action(self, state):\n",
    "        \"\"\" DQN: Input state, output action \"\"\"\n",
    "        \n",
    "        self.representation = self.prepare_state_representation(state)\n",
    "        self.action = self.run_policy(self.representation)\n",
    "        act_slot_response = copy.deepcopy(self.feasible_actions[self.action])\n",
    "        return {'act_slot_response': act_slot_response, 'act_slot_value_response': None}\n",
    "        \n",
    "    \n",
    "    def prepare_state_representation(self, state):\n",
    "        \"\"\" Create the representation for each state \"\"\"\n",
    "        \n",
    "        user_action = state['user_action']\n",
    "        current_slots = state['curr_slots']\n",
    "        kb_results_dict = state['kb_results']\n",
    "        agent_last = state['agent_action']\n",
    "        \n",
    "        ########################################################################\n",
    "        #   Create one-hot of acts to represent the current user action\n",
    "        ########################################################################\n",
    "        user_act_rep =  np.zeros((1, self.act_cardinality))\n",
    "        user_act_rep[0,self.act_set[user_action['diaact']]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #     Create bag of inform slots representation to represent the current user action\n",
    "        ########################################################################\n",
    "        user_inform_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in user_action['inform_slots'].keys():\n",
    "            user_inform_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Create bag of request slots representation to represent the current user action\n",
    "        ########################################################################\n",
    "        user_request_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in user_action['request_slots'].keys():\n",
    "            user_request_slots_rep[0, self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Creat bag of filled_in slots based on the current_slots\n",
    "        ########################################################################\n",
    "        current_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        for slot in current_slots['inform_slots']:\n",
    "            current_slots_rep[0, self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent act\n",
    "        ########################################################################\n",
    "        agent_act_rep = np.zeros((1,self.act_cardinality))\n",
    "        if agent_last:\n",
    "            agent_act_rep[0, self.act_set[agent_last['diaact']]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent inform slots\n",
    "        ########################################################################\n",
    "        agent_inform_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        if agent_last:\n",
    "            for slot in agent_last['inform_slots'].keys():\n",
    "                agent_inform_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Encode last agent request slots\n",
    "        ########################################################################\n",
    "        agent_request_slots_rep = np.zeros((1, self.slot_cardinality))\n",
    "        if agent_last:\n",
    "            for slot in agent_last['request_slots'].keys():\n",
    "                agent_request_slots_rep[0,self.slot_set[slot]] = 1.0\n",
    "        \n",
    "        turn_rep = np.zeros((1,1)) + state['turn'] / 10.\n",
    "\n",
    "        ########################################################################\n",
    "        #  One-hot representation of the turn count?\n",
    "        ########################################################################\n",
    "        turn_onehot_rep = np.zeros((1, self.max_turn))\n",
    "        turn_onehot_rep[0, state['turn']] = 1.0\n",
    "\n",
    "        ########################################################################\n",
    "        #   Representation of KB results (scaled counts)\n",
    "        ########################################################################\n",
    "        kb_count_rep = np.zeros((1, self.slot_cardinality + 1)) + kb_results_dict['matching_all_constraints'] / 100.\n",
    "        for slot in kb_results_dict:\n",
    "            if slot in self.slot_set:\n",
    "                kb_count_rep[0, self.slot_set[slot]] = kb_results_dict[slot] / 100.\n",
    "\n",
    "        ########################################################################\n",
    "        #   Representation of KB results (binary)\n",
    "        ########################################################################\n",
    "        kb_binary_rep = np.zeros((1, self.slot_cardinality + 1)) + np.sum( kb_results_dict['matching_all_constraints'] > 0.)\n",
    "        for slot in kb_results_dict:\n",
    "            if slot in self.slot_set:\n",
    "                kb_binary_rep[0, self.slot_set[slot]] = np.sum( kb_results_dict[slot] > 0.)\n",
    "\n",
    "        self.final_representation = np.hstack([user_act_rep, user_inform_slots_rep, user_request_slots_rep, agent_act_rep, agent_inform_slots_rep, agent_request_slots_rep, current_slots_rep, turn_rep, turn_onehot_rep, kb_binary_rep, kb_count_rep])\n",
    "        return self.final_representation\n",
    "      \n",
    "    def run_policy(self, representation):\n",
    "        \"\"\" epsilon-greedy policy \"\"\"\n",
    "        \n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.num_actions - 1)\n",
    "        else:\n",
    "            if self.warm_start == 1:\n",
    "                if len(self.experience_replay_pool) > self.experience_replay_pool_size:\n",
    "                    self.warm_start = 2\n",
    "                return self.rule_policy()\n",
    "            else:\n",
    "                return self.dqn.predict(representation, {}, predict_model=True)\n",
    "    \n",
    "    def rule_policy(self):\n",
    "        \"\"\" Rule Policy \"\"\"\n",
    "        \n",
    "        if self.current_slot_id < len(self.request_set):\n",
    "            slot = self.request_set[self.current_slot_id]\n",
    "            self.current_slot_id += 1\n",
    "\n",
    "            act_slot_response = {}\n",
    "            act_slot_response['diaact'] = \"request\"\n",
    "            act_slot_response['inform_slots'] = {}\n",
    "            act_slot_response['request_slots'] = {slot: \"UNK\"}\n",
    "        elif self.phase == 0:\n",
    "            act_slot_response = {'diaact': \"inform\", 'inform_slots': {'taskcomplete': \"PLACEHOLDER\"}, 'request_slots': {} }\n",
    "            self.phase += 1\n",
    "        elif self.phase == 1:\n",
    "            act_slot_response = {'diaact': \"thanks\", 'inform_slots': {}, 'request_slots': {} }\n",
    "                \n",
    "        return self.action_index(act_slot_response)\n",
    "    \n",
    "    def action_index(self, act_slot_response):\n",
    "        \"\"\" Return the index of action \"\"\"\n",
    "#         print(\"act_slot_response = {}\".format(act_slot_response))\n",
    "        for (i, action) in enumerate(self.feasible_actions):\n",
    "            if act_slot_response == action:\n",
    "                return i\n",
    "        raise Exception(\"action index not found\")\n",
    "        return None\n",
    "    \n",
    "    \n",
    "    def register_experience_replay_tuple(self, s_t, a_t, reward, s_tplus1, episode_over):\n",
    "        \"\"\" Register feedback from the environment, to be stored as future training data \"\"\"\n",
    "        \n",
    "        state_t_rep = self.prepare_state_representation(s_t)\n",
    "        action_t = self.action\n",
    "        reward_t = reward\n",
    "        state_tplus1_rep = self.prepare_state_representation(s_tplus1)\n",
    "        training_example = (state_t_rep, action_t, reward_t, state_tplus1_rep, episode_over)\n",
    "        \n",
    "        if self.predict_mode == False: # Training Mode\n",
    "            if self.warm_start == 1:\n",
    "                self.experience_replay_pool.append(training_example)\n",
    "        else: # Prediction Mode\n",
    "            self.experience_replay_pool.append(training_example)\n",
    "    \n",
    "    def train(self, batch_size=1, num_batches=100):\n",
    "        \"\"\" Train DQN with experience replay \"\"\"\n",
    "        \n",
    "        for iter_batch in range(num_batches):\n",
    "            self.cur_bellman_err = 0\n",
    "            for iter in range(len(self.experience_replay_pool)/(batch_size)):\n",
    "                batch = [random.choice(self.experience_replay_pool) for i in xrange(batch_size)]\n",
    "                batch_struct = self.dqn.singleBatch(batch, {'gamma': self.gamma}, self.clone_dqn)\n",
    "                self.cur_bellman_err += batch_struct['cost']['total_cost']\n",
    "            \n",
    "            print(\"cur bellman err %.4f, experience replay pool %s\" % (float(self.cur_bellman_err)/len(self.experience_replay_pool), len(self.experience_replay_pool)))\n",
    "            \n",
    "            \n",
    "    ################################################################################\n",
    "    #    Debug Functions\n",
    "    ################################################################################\n",
    "    def save_experience_replay_to_file(self, path):\n",
    "        \"\"\" Save the experience replay pool to a file \"\"\"\n",
    "        \n",
    "        try:\n",
    "            pickle.dump(self.experience_replay_pool, open(path, \"wb\"))\n",
    "            print('saved model in %s' % (path, ))\n",
    "        except(Exception, e):\n",
    "            print('Error: Writing model fails: %s' % (path, ))\n",
    "            print(e         )\n",
    "    \n",
    "    def load_experience_replay_from_file(self, path):\n",
    "        \"\"\" Load the experience replay pool from a file\"\"\"\n",
    "        \n",
    "        self.experience_replay_pool = pickle.load(open(path, 'rb'))\n",
    "    \n",
    "             \n",
    "    def load_trained_DQN(self, path):\n",
    "        \"\"\" Load the trained DQN from a file \"\"\"\n",
    "        \n",
    "        trained_file = pickle.load(open(path, 'rb'))\n",
    "        model = trained_file['model']\n",
    "        \n",
    "        print(\"trained DQN Parameters:\", json.dumps(trained_file['params'], indent=2))\n",
    "        return(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### create an agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent = RequestBasicsAgent(movie_kb, act_set, slot_set, agent_params)\n",
    "agent = AgentDQN(movie_kb, act_set, slot_set, agent_params)\n",
    "agent.set_nlg_model(nlg_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dialog Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "code_folding": [
     24
    ]
   },
   "outputs": [],
   "source": [
    "class DlgManager:\n",
    "    def __init__(self, agent, user, act_set, slot_set, movie_dict):\n",
    "        self.agent = agent\n",
    "        self.user = user\n",
    "        self.act_set    = act_set\n",
    "        self.slot_set   = slot_set\n",
    "        self.movie_dict = movie_dict\n",
    "        self.state_tracker = StateTracker(act_set, slot_set, movie_dict)\n",
    "    \n",
    "    def init_episode(self):\n",
    "        \"\"\" \n",
    "        Refresh state for new dialog \n",
    "        \"\"\"\n",
    "        self.reward = 0\n",
    "        self.episode_done = False\n",
    "        self.state_tracker.init_episode()\n",
    "        self.user_action = self.user.init_episode()\n",
    "        self.state_tracker.update(user_action = self.user_action)\n",
    "        self.agent.init_episode()\n",
    "        if NlgConfig.run_mode < 3:\n",
    "            pass\n",
    "#             print (\"New episode, user goal:\")\n",
    "#             print(json.dumps(self.user.goal, indent=2))\n",
    "#         self.print_function(user_action = self.user_action)\n",
    "        \n",
    "    def print_function(self, agent_action=None, user_action=None):\n",
    "        \"\"\" Print Function \"\"\"\n",
    "            \n",
    "        if agent_action:\n",
    "            if NlgConfig.run_mode == 0:\n",
    "                if self.agent.__class__.__name__ != 'AgentCmd':\n",
    "                    print (\"Turn %d sys: %s\" % (agent_action['turn'], agent_action['nl']))\n",
    "            elif NlgConfig.run_mode == 1:\n",
    "                if self.agent.__class__.__name__ != 'AgentCmd':\n",
    "                    print(\"Turn %d sys: %s, inform_slots: %s, request slots: %s\" % (agent_action['turn'], agent_action['diaact'], agent_action['inform_slots'], agent_action['request_slots']))\n",
    "            elif NlgConfig.run_mode == 2: # debug mode\n",
    "                print(\"Turn %d sys: %s, inform_slots: %s, request slots: %s\" % (agent_action['turn'], agent_action['diaact'], agent_action['inform_slots'], agent_action['request_slots']))\n",
    "                print (\"Turn %d sys: %s\" % (agent_action['turn'], agent_action['nl']))\n",
    "            \n",
    "            if NlgConfig.auto_suggest == 1:\n",
    "                print('(Suggested Values: %s)' % (self.state_tracker.get_suggest_slots_values(agent_action['request_slots'])))\n",
    "        elif user_action:\n",
    "            if NlgConfig.run_mode == 0:\n",
    "                print (\"Turn %d usr: %s\" % (user_action['turn'], user_action['nl']))\n",
    "            elif NlgConfig.run_mode == 1: \n",
    "                print (\"Turn %s usr: %s, inform_slots: %s, request_slots: %s\" % (user_action['turn'], user_action['diaact'], user_action['inform_slots'], user_action['request_slots']))\n",
    "            elif NlgConfig.run_mode == 2: # debug mode, show both\n",
    "                print (\"Turn %d usr: %s, inform_slots: %s, request_slots: %s\" % (user_action['turn'], user_action['diaact'], user_action['inform_slots'], user_action['request_slots']))\n",
    "                print (\"Turn %d usr: %s\" % (user_action['turn'], user_action['nl']))\n",
    "            \n",
    "            if self.agent.__class__.__name__ == 'AgentCmd': # command line agent\n",
    "                user_request_slots = user_action['request_slots']\n",
    "                if 'ticket'in user_request_slots.keys(): del user_request_slots['ticket']\n",
    "                if len(user_request_slots) > 0:\n",
    "                    possible_values = self.state_tracker.get_suggest_slots_values(user_action['request_slots'])\n",
    "                    for slot in possible_values.keys():\n",
    "                        if len(possible_values[slot]) > 0:\n",
    "                            print('(Suggested Values: %s: %s)' % (slot, possible_values[slot]))\n",
    "                        elif len(possible_values[slot]) == 0:\n",
    "                            print('(Suggested Values: there is no available %s)' % (slot))\n",
    "                else:\n",
    "                    kb_results = self.state_tracker.get_current_kb_results()\n",
    "                    print ('(Number of movies in KB satisfying current constraints: %s)' % len(kb_results))\n",
    "                    \n",
    "                    \n",
    "    \n",
    "    def step(self, record_training_data=True):\n",
    "        \"\"\" \n",
    "        initiates each subsequent exchange between agent and user (agent first) \n",
    "        \"\"\"\n",
    "        ########################################################################\n",
    "        #   CALL AGENT TO TAKE HER TURN\n",
    "        ########################################################################\n",
    "        self.state = self.state_tracker.get_state_for_agent()\n",
    "        self.agt_action = self.agent.state_to_action(self.state)\n",
    "        \n",
    "        ########################################################################\n",
    "        #   Register AGENT action with the state_tracker\n",
    "        ########################################################################\n",
    "        self.state_tracker.update(agent_action=self.agt_action)\n",
    "        \n",
    "        self.agent.add_nl_to_action(self.agt_action) # add NL to Agent Dia_Act\n",
    "#         self.print_function(agent_action = self.agt_action['act_slot_response'])\n",
    "        \n",
    "        ########################################################################\n",
    "        #   CALL USER TO TAKE HER TURN\n",
    "        ########################################################################\n",
    "        self.sys_action = self.state_tracker.dialog_history_dictionaries()[-1]\n",
    "        self.user_action, self.episode_done, dialog_status = self.user.next(self.sys_action)\n",
    "        self.reward = self.reward_function(dialog_status)\n",
    "        ########################################################################\n",
    "        #   Update state tracker with latest user action\n",
    "        ########################################################################\n",
    "        if not self.episode_done:\n",
    "            self.state_tracker.update(user_action = self.user_action)\n",
    "#             self.print_function(user_action = self.user_action)\n",
    "\n",
    "        ########################################################################\n",
    "        #  Inform agent of the outcome for this timestep (s_t, a_t, r, s_{t+1}, episode_done)\n",
    "        ########################################################################\n",
    "        if record_training_data:\n",
    "            self.agent.register_experience_replay_tuple(self.state, self.agt_action, self.reward, self.state_tracker.get_state_for_agent(), self.episode_done)\n",
    "        \n",
    "        return (self.episode_done, self.reward)\n",
    "\n",
    "    def reward_function(self, dialog_status):\n",
    "        \"\"\" Reward Function 1: a reward function based on the dialog_status \"\"\"\n",
    "        if dialog_status == DlgManagerConfig.FAILED_DIALOG:\n",
    "            reward = -self.user.max_turn #10\n",
    "        elif dialog_status == DlgManagerConfig.SUCCESS_DIALOG:\n",
    "            reward = 2*self.user.max_turn #20\n",
    "        else:\n",
    "            reward = -1\n",
    "        return reward\n",
    "    \n",
    "    def reward_function_without_penalty(self, dialog_status):\n",
    "        \"\"\" Reward Function 2: a reward function without penalty on per turn and failure dialog \"\"\"\n",
    "        if dialog_status == UserSimulatorConfig.FAILED_DIALOG:\n",
    "            reward = 0\n",
    "        elif dialog_status == UserSimulatorConfig.SUCCESS_DIALOG:\n",
    "            reward = 2*self.user.max_turn\n",
    "        else:\n",
    "            reward = 0\n",
    "        return reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dlg_manager = DlgManager(agent, user, act_set, slot_set, movie_kb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Param for Running Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "status = {'successes': 0, 'count': 0, 'cumulative_reward': 0}\n",
    "# the size of validation set\n",
    "simulation_epoch_size = 50\n",
    "# the number of epochs for warm start \n",
    "warm_start_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def simulate_epoch(num_epoch):\n",
    "#     \"\"\"\n",
    "#     run num_epoch of epochs\n",
    "#     \"\"\"\n",
    "#     num_succ = 0\n",
    "#     accu_reward = 0\n",
    "#     accu_turns = 0\n",
    "#     res = {}\n",
    "#     for i in range(1, num_epoch+1):\n",
    "#         dlg_manager.init_episode()\n",
    "#         done = False\n",
    "#         while not done:\n",
    "#             episode_done, reward = dlg_manager.step()\n",
    "#             accu_reward += reward\n",
    "#             if episode_done:\n",
    "#                 accu_turns += dlg_manager.state_tracker.turn_count\n",
    "#                 if reward > 0:\n",
    "#                     num_succ += 1\n",
    "#                     print(\"Episode Success!\")\n",
    "#                 else:\n",
    "#                     print(\"Episode Fail!\")\n",
    "#     res['success_rate'] = float(num_succ)/num_epoch\n",
    "#     res['ave_reward'] = float(accu_reward)/num_epoch\n",
    "#     res['ave_turns'] = float(acc_turns)/num_epoch\n",
    "#     print(\"simulation success rate %s, ave reward %s, ave turns %s\" % (res['success_rate'], res['ave_reward'], res['ave_turns']))\n",
    "#     return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def run_episodes(num_episode, status):\n",
    "    num_success = 0\n",
    "    accu_reward = 0.\n",
    "    accu_episodes = 0.\n",
    "    for i in range(1, num_episode+1):\n",
    "        print(\"\\nEpisode {} starts!\".format(i))\n",
    "        dlg_manager.init_episode()\n",
    "        done = False\n",
    "        while not done:\n",
    "            done, reward = dlg_manager.step()\n",
    "            accu_reward += reward\n",
    "            if done:\n",
    "                if reward > 0: num_success += 1\n",
    "                accu_episodes += dlg_manager.state_tracker.turn_count\n",
    "        print(\"Progress: %s / %s, Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (i+1, num_episode, num_success, i+1, float(accu_reward/(i+1)), float(accu_episodes)/(i+1)))\n",
    "    print(\"Success rate: %s / %s Avg reward: %.2f Avg turns: %.2f\" % (num_success, num_episode, accu_reward/num_episode, float(accu_episodes)/num_episode))\n",
    "    status['successes'] += num_success\n",
    "    status['count'] += num_episode\n",
    "    return True if reward>0 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Episode 1 starts!\n",
      "Progress: 2 / 1, Success rate: 1 / 2 Avg reward: 36.50 Avg turns: 8.00\n",
      "Success rate: 1 / 1 Avg reward: 73.00 Avg turns: 16.00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<h3>Success</h3> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_episodes = 1\n",
    "agt = 2\n",
    "success = run_episodes(num_episodes, status)\n",
    "display.HTML('<h3>{}</h3> '.format(\"Success\" if success else \"Fail\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
